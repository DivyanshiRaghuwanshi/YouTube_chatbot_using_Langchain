{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEBSbRsn-_UJ"
   },
   "source": [
    "Install libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svRmzHD--6_p",
    "outputId": "9e2fc83c-f0e0-4d83-de37-576fa0a04655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.0/485.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q youtube-transcript-api langchain-community langchain-openai \\\n",
    "               faiss-cpu tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fL7P8URRST_e",
    "outputId": "92912691-a134-44eb-fbcf-1185657668aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.3.74)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.21.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.34.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.7)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n",
      "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "Successfully installed langchain-huggingface-0.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKd6Q3RvDkfF",
    "outputId": "83d7943e-6391-49ef-a063-83376f982669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube-transcript-api) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube-transcript-api) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cWDriznT_Rgl"
   },
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bp9YJzEaEuQm",
    "outputId": "9873dfeb-86f7-4960-ea50-f74398b7bda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: youtube-transcript-api\n",
      "Version: 1.2.2\n",
      "Summary: This is an python API which allows you to get the transcripts/subtitles for a given YouTube video. It also works for automatically generated subtitles, supports translating subtitles and it does not require a headless browser, like other selenium based solutions do!\n",
      "Home-page: https://github.com/jdepoix/youtube-transcript-api\n",
      "Author: Jonas Depoix\n",
      "Author-email: jonas.depoix@web.de\n",
      "License: MIT\n",
      "Location: /usr/local/lib/python3.12/dist-packages\n",
      "Requires: defusedxml, requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bbBTetYFCAK",
    "outputId": "cea1dd3d-49c8-4468-f0d8-72c77e99f17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube_transcript_api._api\n",
      "{'__module__': 'youtube_transcript_api._api', '__init__': <function YouTubeTranscriptApi.__init__ at 0x7fcd547eff60>, 'fetch': <function YouTubeTranscriptApi.fetch at 0x7fcd551bef20>, 'list': <function YouTubeTranscriptApi.list at 0x7fcd551e8180>, '__dict__': <attribute '__dict__' of 'YouTubeTranscriptApi' objects>, '__weakref__': <attribute '__weakref__' of 'YouTubeTranscriptApi' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "print(YouTubeTranscriptApi.__module__)\n",
    "print(YouTubeTranscriptApi.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qp_H0n2X_aX6"
   },
   "source": [
    "#Step1(a): Indexing-(Document Ingestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0myr-ZRp_Ww1",
    "outputId": "8e582ad1-a856-476d-d06f-d79f4dbc2255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello listeners welcome back to Luke's English podcast how are you today I hope you're doing fine you're doing all right I hope so um lovely day here not that it's important really in the grand scheme of things but I thought you might like to know the sun is shining it's quite a nice warm afternoon here in October when I'm recording this slightly unseasonably warm but Pleasant nonetheless let me tell you about this episode that you're about to listen to so first of all there's a PDF for this one and you can get it by just uh clicking the link that you'll find in the episode description just check the show notes and you'll find a link there for the PDF which you can download if you want to and uh if you like you can follow along with me um you can read while you listen uh or you can just go back and check the PDF later because there will be like loads of vocabulary in this episode and uh a vocabulary list and texts which have the the vocab highlighted and stuff like that so it would be I think a good idea for you to go back to uh the PDF and check out all that vocab and perhaps you know review it later it'll definitely help you remember it anyway Link in the description for the PDF and I'm going to start reading from the PDF right now so here we go in 5 4 3 2 1 so uh this is a podcast for Learners of English around the world in my episodes I talk about almost anything but my aim is always to help you learn English and perhaps to entertain or stimulate you a bit in the process in this episode I'll be talking about the cheerful subject of the existential threat of AI to human civilization so I'm going to discuss the subject of artificial intelligence and the impact it will have on human civilization in the foreseeable future both good and bad I'll explore and disc the topic in some detail and we'll explain some vocabulary as we go hopefully this will be interesting as well as useful for your English as it will give you plenty of words and phrases that you can use to discuss this subject which everybody is talking about AI is everywhere at the moment but can you say it yes can you actually say AI I've noticed a lot of my students talking about AI in English lessons the topic comes up a lot but my students don't actually pronounce this correctly so I think this would be a good place to start just pronounce AI right so a I repeat it after me a I but what happens when those two letters or sounds are spoken one after the other quickly is it sounds like this ai ai all right AI otherwise known as AI so we're talking about AI artificial intelligence so AI is everywhere and will only be more present in our lives in the future of course we're all aware of chat GPT and a lot of us use it all the time now including me I use it as an English teacher especially to generate texts to present language in context it's incredibly useful as a way of generating example sentences in English as well as plenty of other interesting um texts and things uh so we're all used to a certain amount of AI in our lives now and I should say that obviously chat GPT is just one small example of um the various forms of AI that exist and will exist but we're all used to a certain amount of AI in our lives now and we're probably aware that there are various opinions of AI going around both positive and negative like with most technology it'll probably have positive and negative impacts but I wonder if we if we all really realize the full extent that AI will change our world over the next few years and decades I mean it's insane really if you look at the different predictions and without being alarmist or paranoid or anything we could be looking at deeply profound changes to everything as a result of the continued development of AI alarmist if you are alarmist it means that you are perhaps taking a slightly um panicked uh view of things like you're raising the alarm ringing an alarm as if to say this is an emergency this is this is really serious when in fact it's not that serious and it's not really an emergency so that's what it means to be alarm IST is to perhaps maybe overreact about something um and you know overreact about the seriousness or the um uh the level of emergency going on so without being alarmist or paranoid or anything we could be looking at deeply profound changes to everything as a result of the continued development of of AI that's what this episode is about that's what I really want to talk about today and I was inspired to do this episode after I watched an interview with one of the world's leading experts on AI um I don't know you might have seen it too it's a video that's been going around on YouTube BBC News night interview with um what with who is described as uh The Godfather of AI so I found it absolutely fascinating as well as quite disturbing so it's an interview with the Nobel prizewinning Godfather of AI Jeffrey Hinton the interview took place earlier this year on BBC News night which is an evening news and current affairs TV show on the BBC the interview was then uploaded to the BBC News Night YouTube channel this month October that's the month when I'm recording this which is where I saw it so this is from the video description this is a description of the interview so Jeffrey Hinton former vice president of Google and sometimes referred to as the Godfather of AI I has recently won the 2024 Nobel physics prize so this guy used to be vice president of Google and is or has been referred to as the Godfather of AI so this is a person who is definitely an expert in this subject he recently won the 2024 Nobel physics prize he resigned from Google in 2023 he resigned that means he quit his job um not sure exactly the reasons why but he stepped down from his position at Google uh last year and has warned about the dangers of machines that could outsmart humans okay by the way if you're looking at the the PDF you'll see that some words and phrases are highlighted in a sort of orange highlight highlight highlighter um and these are bits of vocab that I'll be explaining as I go along and which are summarized as well at the end of the episode so um um uh he resigned from Google in 2023 and has warned about the dangers of machines that could outsmart humans so to outsmart humans means to to be more intelligent than humans so he's talking about the danger the possible the possibility that machines or AI in the future could become more intelligent than humans could outsmart humans so let me summarize the video and then go through the script of the interview giving my explanations and comments and of course explaining and highlighting certain bits of vocabulary if there's time I'll do a vocabulary recap at the end and certainly on the PDF you'll see a full vocabulary list with definitions examples and comments so that uh BBC News night interview it's available on on YouTube I'm not going to play the audio of the interview directly in this episode but I can give you a summ of the video and I will read from the transcript of the video so here's a summary of the video it's this basically experts believe AI will exceed human intelligence in 5 to 20 years raising concerns about potential control and existential threats okay so experts believe that AI will exceed human intelligence in 5 to 20 years it'll exceed human intelligence meaning it'll it will become greater than right it'll go higher human intelligence is here at this level and AI will get to a higher level than that it will exceed human intelligence in up to 20 years raising concerns meaning making people concerned so if you raise concerns about something it means that people's concerns or or worries about a certain subject are raised they go up right to raise something means to make something go up rise means go up so people's concerns rise and uh this information raises people's concerns about potential control and existential threats potential means it's it's possible it could happen in the future it's something that is um that's a possibility for the future so potential threats threats that could happen in the future uh we're talking about potential control threats meaning uh whether we will be able to control this technology and existential threats meaning threats to our very existence as the human race which sounds a little bit what's the word for it as I said paranoid maybe alarmist but actually when you hear what uh this man has to say you realize that it's actually quite reasonable and quite rational to have these these fears about these threats potential dangers so here are the highlights of what was said in the interview and I will expand on these things later in the episode but here's a here's a general overview of the main points so first of all AI is expected to exceed human intelligence soon as I said many experts are concerned about the existential threat posed by Advanced AI the existential threat posed by Advanced ai ai the AI represents or is or poses presents a big threat to human civilization our very existence is threatened by this so it poses an existential threat large language models May operate similarly to human brains so when we talk about large language models we're talking about things like chat GPT which are forms of AI that are based on um inputting massive amounts of language data into the system right so essentially uh chat GPT is a is a large large language model the basis of its intelligence is language that it is fed massive samples of language which it then processes and this is the basis of its intelligence so large it's difficult to understand that I find that really complicated to understand but I also find it absolutely fascinating because of this large language models like chat GPT May operate similarly to human brains so this is essentially the idea that something like chat GPT and the human brain might actually operate in a really similar way because maybe language is the key to understanding the way that human minds or human brains process things that language is absolutely Central to our intelligence and if you create a machine that sort of is based Bas on language that um uses its ability to process language as the core of its intelligence you might end up with something that's very similar to a human brain which I find fascinating um we continue so the risk of AI taking autonomous lethal actions is significant which is rather terrifying so the risk of artificial intelligence taking autonomous legal uh not legal autonomous lethal actions so lethal actions are actions which will um kill people so lethal refers to something that could kill um so lethal actions are things that could kill people and autonomous legal lethal actions autonomous means that the AI chooses to do it on its own right it doesn't need to be told to do it it just kind of does it on its own or maybe does it as a consequence of some other um uh instruction or or order that it's being given but basically we're talking about AI choosing to kill people and the risk of this is significant significant meaning uh sort of large in its importance okay so there's a there's actually a large chance that um the AI could actually decide to kill humans again sounds paranoid and alarmist but you know just wait and see so International regulation of military AI applications is lacking so International regulation this is basically applying rules to control things so you know different jurisdictions Global or local you know whether it's like EU law or some sort of global convention um these this is what we mean by regulation so systems of rules and laws to control things so International regulation of military AI this is artificial intelligence used in military applications so when we say applications that means not applications on your phone but in in uses the ways in which uh in this case AI is used so that's military applications that would be using AI for military purposes so regulation of this is lacking so there's not enough control or regulation that would limit the application or use of AI in military situations this is this this is one of the most terrifying aspects of this also AI could widen the wealth Gap right the Gap this is the gap between the W the the rich and the poor okay the the fact that there's you know a huge difference a huge disparity between those people who are rich and those people who are poor and I mean really the way it works is that there there's an increasingly small number of people who are becoming increasingly Rich so you get you get to a situation where there's a kind of a a small minority very small minority who have uh most of the money and then all the other people uh relatively speaking have very little money so you end up with this big gap between poor people and rich people so there's this huge imbalance in society so AI could widen this Gap make it wider make it bigger affecting Society negatively and plumbing may be one of the safest jobs in the age of AI Plumbing refers to uh all of the systems in someone's home normally a home or a building or something all the systems that deal with water so all the pipes in your kitchen all the pipes in your bathroom that transfer water around your apartment something as basic and mechanical as that so that's Plumbing this might be actually one of the safest jobs that you could choose to do in the future in the age of AI okay so this is it's pretty serious stuff okay it's pretty serious stuff it's pretty fascinating stuff it's slightly disturbing let's get into the interview transcript okay so now read out the transcript of the interview listen and follow and I'll go through this word by word afterwards so first of all let's just let me just read through the script I'll kind of reconstruct the interview see if you can follow it all and yeah we'll be going through this script line by line um later in the episode okay so let's get let's get started so here's the transcript so uh fil Islam that's the interviewer talks to Jeffrey Hinton about the threat of AI on BBC News night that doesn't mean the the fact that AI could be a threat to BBC News night this just means that the interview was on BBC News night I think you understand right so uh here we go so this is this is where the script begins so I began by asking Jeffrey Hinton whether he thought the world is getting to grips with the issue of AI or if he's as concerned as ever so this is Jeffrey Hinton I'm still as concerned as I have been but I'm very pleased is that the world is beginning to take it seriously in particular they're beginning to take the existential threat seriously that these things will get smarter than us and we have to worry about whether they'll want to take control away from us that's something we should think seriously about and people now take that seriously a few years ago they thought it was just science fiction and the interviewer and from your perspective from having worked at the top of this having developed some of the theories underpinning all of this explosion in AI that we're seeing that existential threat is real yes so some people think these things don't really understand they're very different from us they're just using some statistical tricks that's not the case these big language models for example the early ones were developed as a theory of how the brain understands language they're the best theory we've currently got of how the brain understands language we don't really understand either how they work or how the brain works in detail but we think probably they work in Fairly similar ways what is it that's triggered your concern it's been a combination of two things playing with the large chat Bots particularly one at Google before chat gp4 but also with gp4 they're clearly very competent they clearly understand a lot they have a lot more knowledge than any person they're like a not very good expert at more or less everything so that was one worry and the second was coming to understand the way in which they're a superior form of intelligence because you can make many copies of the same neural network each copy can look at a different bit of data and then they can all share what they've learned so imagine if we had 10,000 people they could all go off and do a degree in something share what they'd learned efficiently and then we'd all have 10,000 degrees we'd know a lot then we can't share knowledge nearly as efficiently as different copies of the same neural network can so the key concern here is that it could exceed human intelligence indeed massively exceed human intelligence very few of the experts are in doubt about that almost everybody I know who's an expert on AI believes that they will exceed human intelligence it's just a question of when and at that point it's really quite difficult to control them well we don't know we've never dealt with something like this before there are a few experts like my friend Yan Lun who thinks it'll be no problem we'll give them the goals and it'll be no problem they'll do what we say they'll be be subservient to us there are other experts who think absolutely they'll take control given this big spectrum of opinions I think it's wise to be cautious I think there's a chance they'll take control and it's a significant chance it's not like 1% it's much more interviewer could they not be contained in certain areas like scientific research but not for example the armed for forces maybe but actually if you look at all the current legislation including the European legislation there's a little clause in all of it that says that none of this applies to military applications governments aren't willing to restrict their own uses of it for defense interviewer I mean there's been some evidence even in current conflicts of the use of AI in generating thousands and thousands of targets yes I mean that's happened since I mean that's happened since you started warning about AI is that the sort of pathway that you're concerned about I mean that's the thin end of the wedge what I'm most concerned about is when these things can autonomously make the decision to kill people so robot soldiers yeah those or drones and the like and it may be we can get something like the Geneva conventions to regulate them but I don't think that's going to happen until after very nasty things have happened there's an analogy here with the Manhattan Project and with Oppenheimer if we restrain ourselves from military use in the G7 Advanced democracies what's going on in China what's going on in Russia interviewer yes it has to be an international agreement but if you look at chemical weapons the international agreement for chemical weapons has worked quite well I mean do you have any sense of whether the shackles are off in a place like Russia well Putin said some years ago that whoever controls AI controls the world so I imagine they're working very hard the West is probably well ahead of them in research we're probably still slightly ahead of China but China is putting more resources in in terms of military uses of AI I think there's going to be a race interviewer it sounds very theoretical this argument uh This Thread of argument but you really are quite worried about extinction level events we should distinguish these different risks the risk of using AI for autonomous lethal weapons doesn't depend on AI being smarter than us that's a quite separate risk from the risk that the AI itself will go Rogue and try to take over I'm worried about both things things the autonomous weapons are clearly going to come but whether AI goes Rogue and tries to take over is something we may be able to control or we may not we don't know and so at this point before it's more intelligent than us we should be putting huge resources into seeing whether we're going to be able to control it interviewer what sort of society do you see evolving which jobs will still be here yes I'm very worried about AI taking over lots of mundane jobs and that should be a good thing it's going to lead to a big increase in productivity which leads to a big increase in wealth and if that wealth was equally distributed that would be great but it's not going to be in the systems we live in that wealth is going to go to the rich not to the people whose jobs get lost and that's going to be very bad for society I believe so it's going to increase the gap between rich and poor which increases the chances of right-wing populists getting elected interviewer so to be clear you think that the societal impacts from the changes in jobs could be so profound that we may need to rethink the politics of I don't know the benefit system inequality absolutely Universal basic income yes I certainly believe in Universal basic income I don't think that's enough enough though because a lot of people get their self-respect from the job they do and if you put everybody on universal basic income that solves the problem of them starving and not being able to pay the rent but it doesn't solve the self-respect problem so what you just try to the government needs to get involved I mean it's not how we do things in Britain we tend to sort of stand back and let the economy decide the winners and losers Yes actually I was consulted by people in Downing Street and I advised them that Universal basic income was a good idea interviewer and there is you said 10 to 20% risk of them taking over are you more certain that this is going to have to be addressed in the next 5 years next Parliament perhaps my guess is between 5 and 20 years from now there's a probability of about half that we'll have to confront the problem of them trying to take over interviewer are you particularly impressed by the efforts of governments so far to try and re this in I'm impressed by the fact that they're beginning to take it seriously I'm unimpressed by the fact that none of them is willing to regulate military uses and I'm unimpressed by the fact that most of the regulations have no teeth interviewer do you think that the tech companies are letting down their guard on safety because they need to be the winner in this race for AI I don't know about the tech companies in general I know quite a lot about Google because I used to work there Google was very concerned about these issues and Google didn't release the big chat Bots it was concerned about its reputation if they told lies but as soon as open AI went into business with Microsoft and Microsoft put chat Bots into being Google had no choice so I think the competition is going to cause these things to be developed rapidly and the competition means that they won't put enough effort into safety interviewer people parents talk to their children give them advice on the future of the economy what jobs they should do what degrees they should do it seems like the world is being thrown up in the air by this by the world that you're describing what would you advise somebody to study now to kind of surf this wave I don't know because it's clear that a lot of midlevel intellectual jobs are going to disappear and if you ask which jobs are safe my best bet about a job that's safe is Plumbing because these things aren't yet very good at physical manipulation that will probably be the last thing they're very good at and driving what about driving no driving no that's hopeless that's been slower than expected but it's going to go journalism might last a little bit longer but I think think these things are going to be pretty good journalists quite soon and probably quite good interviewers too okay well thank you very much for your time you're welcome right so there you go that was the script of the interview itself now I will go through that transcript word by word in a moment helping you to understand everything but first let's look at the key insights from the interview so this is another summary let's say of the main points of the interview but just expanded slightly with some of my thoughts and comments Excuse me while I drink some tea Excuse me while I drink some tea excuse me little Jimmy Hendrick's uh moment okay so here are those key insights from the interview first of all impending intelligence shift shift here meaning a movement obviously a movement from humans to AI most experts agree that AI will surpass human intelligence in the coming years highlighting the urgency or importance of understanding its implications super intelligent AI might be a threat to us or it might not but since there's potentially a 50/50 chance of it being dangerous to us it would be wise to be cautious about it how and why would it be a threat to us um is a question now it might not be the Sci-Fi version which is basically like what we've seen in the movies you know AI suddenly decides that humans Must Die For some reason so might not be that version but AI could still destabilize our society severely in a variety of ways uh control challenges as AI becomes more competent controlling its actions may become increasingly difficult raising ethical and existential questions so this is this is the classic science fiction storyline that we've seen in films like the Terminator and the Matrix the AI becomes self-aware and can't be controlled and then it sees humans as a threat to its existence or perhaps it identifies Humanity as a problem that needs to be solved it's kind of like The Avengers Age of Ultron situation Tony Stark develops a form of artificial intelligence um as a as as a tool to help protect the Earth but for some reason it becomes evil and decides that uh Humanity needs to be stopped right to be fair maybe that will happen maybe superintelligent AI will see humans as a problem that needs to be solved continuing the PDF to be fair overpopulation and human actions are probably largely to blame for environmental and societal collapse so who knows maybe AI will consider us to be a threat and will take action to stop us destroying everything perhaps it will be like Thanos from Ventures Infinity war and will decide that half of humanity needs to be wiped out in order to guarantee the survival of the human race as a whole I mean who knows but as I said it might not be as simple as AI choosing to kill all humans it might be that human life is put in danger as a consequence of the things AI does especially if we can't control it uh cognitive parallels cognitive meaning relating to the way the mind works parallels meaning similar things the structure of large language models like chat GPT mirrors cognitive processes in the human brain so it mirrors it it's like very similar to it it reflects it it's almost exactly the same as cognitive processes or thinking processes in the human brain suggesting they may possess unique forms of understanding so maybe even uh AI large language models like this might get might have quite a profound understanding of how we think and what it's like to be human um maybe our ability to process languages is Central to how our intelligence works and making AI that processes language the same way as we do is a way of kind of reverse engineering humanlike intelligence basically perhaps AI will think just like humans do maybe it will be a lot more similar to humans than we realize we could be looking at intelligences that oper operate in a similar way to human minds but with much greater capacity for complex decision making multitasking memorizing processing and calling Upon A much wider resource of knowledge that most um than most human individuals can have in their brains so these things could think just like humans but with a way greater capacity for everything memorizing drawing upon Collective knowledge processing things quickly multitasking you know sort of superhuman stuff um then we move on to the autonomous weapons risk so the potential for AI to autonomously make lethal decisions that means choosing to do it on its own poses or presents a severe risk necessitating immediate regulatory attention so this means that we really need to start stepping in and making Global laws that limit the use of AI in uh military conflicts and it's obvious why right I mean we're looking at an arms race just like um you know just like the oldfashioned arms race of the Cold War the space race and all that stuff um but you know um there's a significant risk of of you know because um any regulations about AI they always have a clause in in the law that sort of say actually but none of these rules apply to military AI because everyone is so concerned about defending themselves or trying to compete with uh Rivals uh in on Earth who might be developing the the technology more quickly because no one wants to be in a situation where suddenly they're faced with an enemy who's got more sophisticated artificial intelligence and using it for military purposes because then you know they take over the world right but we need to find a way for the for Earth to agree on a set of regulations a bit like the way we've done for chemical weapons there are international laws that regulate the use of chemical weapons there are bizarrely there are laws and rules for war you know there are such things as war crimes war is a defined thing and uh we try to make sure that Nations even when they're fighting against each other uh comply with these laws as much as possible and in a sense when a nation breaks those laws they instantly become the bad guy you know the it's interesting the way that Nations wage war and take military actions and they're constantly on sort of uh managing their position in the conflict and trying not to be the bad guy or trying not to prove that they are let other people prove that they're the bad guy in the situation and certainly breaking certain International laws that regulate military conflicts that's a a definite sign that if you're doing that then you're you know you're probably the bad guy in the situation anyway so um we need to take immediately immediate action in terms of making regulations laws um that limit the use of um AI in military situations so continuing the PDF AI is definitely being used for military purposes and it's already being used and this is terrifying when you consider how efficient and effective it could be um and that's and that's relating to not just AI being um like uh Ultron from The Avengers movie which is a form of technology that becomes self-aware like Ultron or Skynet in The Terminator uh films that it becomes self-aware and then decides to have a robot versus Humans War rather it's reg making sure that humans controlling AI don't aren't able to to use that AI to wipe out their enemies in extremely efficient and quite horrifying ways um what a jolly subject for an episode of the podcast perhaps I'll go back to telling terrible jokes in the next episode but you know I just feel like I had to talk about this I watched this video and I was just like stunned by it I mean all this sort of thing has been in my mind and I'm sure that you're the same that you read these things and it's just kind of like shocking the the things that they're talking about and there stuff that's normally just reserved for science fiction you think oh it's just a kind of a a dramatic science fiction story but this is this stuff is becoming alarmingly close to reality um let's move on to the next point which is global regulation gaps which is what what I've been talking about current International agreements lack enforceability to enforce law means to basically apply law and actually make it work for example the police can enforce law or courts can enforce law essentially um finding people guilty of crimes if these laws are broken so this is this is how we talk about the enforceability enforcing law applying law in the real world so current International agreements lack enforceability regarding military uses of AI so it it basically the the the the laws are not quite strong enough or clear enough enough to be able to actually control people's behavior potentially leading to unchecked advancements by Nations right um unchecked meaning unregulated the idea of humans controlling lethal AI with no regulations is more frightening than the idea of AI autonomously trying to wipe out humans it's more of a realistic concern that one side or one faction in a situation would suddenly get their hands on extremely Advanced and sophisticated AI weaponry and they would use it with devastating consequences um just like in the nuclear age there is already an arms race underway involving AI in which competing power blocks are racing to develop lethal AI systems to prevent one faction having Supremacy the result could be that AI becomes armed dangerous fully developed and poised to wreak there's a happy thought for you also economic disparities so it's not just Skynet and Terminators being sent back from the future to kill Housewives or whatever um we're talking about economic effects as well right which could be I mean is likely to be just as damaging so the rise of AI threatens to deepen existing economic equalities so economic inequalities did I say inequalities I think so so existing economic inequalities so again talking about the gap between the rich and the poor the The Haves and the Have Nots the rise of AI is not going to balance this out in fact it's going to exacerbate it it's going to it's likely to make this much worse prompting considerations for Universal basic income and societal Reformation Universal basic income is essentially that everyone gets given a certain amount of money to live on everyone is given even if they don't have work everyone is provided with enough money to help them survive right this is the concept of universal basic income because if you don't then you will see large large sections of society essentially falling into terrible levels of poverty as a result of the um the inequality the the economic inequality in society so you essentially hold up all human Civilization by just you know basically just giving them money and it also makes sure that the money moves through the economy so what we what we mean here is that when a small minority of of people get basically all the money like this is when at the end of a game of Monopoly when your sister who this time has won because she got all the orange properties all the red properties and she got the dark blue properties and the purple ones as well why not she won all she's got all of that stuff and in the end she has everything she has all the money the game is over at that point and it's the same in the economy if you get to that situation where you've got your 0.1% who have everything pretty much they have all of the property they've got all the money they own all the businesses everything Society will not work it will fall apart because you need the wheels to turn you need the whole system to keep going you need you know those business owners need customers to spend their money the the the you need liquidity in the system you need the money to constantly be moving and so it would necessitate essentially these people who've got everything going all right well we'll give you we'll give you loads of loads of money it wouldn't be loads we'll give you money just to keep this the the the economy turning it's a bit like if you if your sister wins a game of Monopoly and she's she goes no no I don't want to stop so I'll just give you loads more money every round I'll give you £500 just so we can keep playing the game it's kind of like that but um Jeffrey Hinton is that his name he actually believes Universal basic income is a good idea ultimately so we we we're talking about prompting uh considerations for Universal basic income and societal Reformation Reformation meaning reforming Society changing so Society in some important big way um job security while many intellectual jobs may vanish right that's a lot of them including English teaching quite quite possibly although what do you think would you could you really um when will you um give up Luke's English podcast for the latest AI driven show which you can create create yourself you know that's the future of all of this stuff that instead of having to wait for the next episode of Luke's English podcast and instead of having to essentially um accept what I give you you could probably just go into some podcast making software I mean you can do it already you go into some podcast making software and just type in can you make an episode of Luke's English podcast about the subject of I don't know donuts and make it 30 minutes long to fit my morning commute to work okay and include a joke every 45 seconds and it will do it and it'll be exactly what you wanted and you could just do that every single time and then after maybe the first 10 times you've generated them you just say to it just keep making episodes like this you know the kind of thing I like just go on and it'll keep doing it and then there's that or will you continue to listen to the real Luke's English podcast which one so I mean that's just an example of how my job as a podcaster could vanish my job as an English teacher of course could I mean it's already under threat from um uh AI uh language models I mean I use it now as a teaching assistant but at some point that teaching assistant is going to get to a stage where it can just replace me completely but you know could you would you would you would you reject me that easily anyway while many intellectual jobs may vanish practical skills like Plumbing which is what I talked about before fixing repairing water pipes in a home or in the street something like that will likely remain safe emphasizing the need for future job Readiness Readiness means being ready okay so that's again an overview of the things that were said in the interview we're going to go through the interview in a bit and look at the vocab and stuff but at this point I would like to ask you what do you think what do you think of all this what's your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction and you could write your reaction in the comments section now maybe you feel like you want to make criticisms like these ones and I'm about to read out some comments which are based on things I I read in the comments section under the BBC video so maybe you want to make criticisms like this maybe you want to say things like this maybe he maybe this expert should have done something about this earlier when he had the chance he's the Godfather of AI he helped to develop all this maybe he should have uh thought about this um and done something about it when he had the chance maybe you criticize this expert or maybe you'll say something like this as a former Google employee he's a mainstream globalist blah blah blah blah blah something like that you probably get triggered by the fact he works for Google and you might go off on some rant about him being whatever some globalist thing you I don't know I don't know do you know are you triggered by any of it or maybe you're you're one of those sorts of people who sort of says you know what it's I think it's all overblown nonsense it's all alarmist nonsense there's nothing to be afraid of or something like new technology is always disruptive but it's all right no one everyone was worried when the printing press was in in invented everyone was concerned when the radio is invented when uh Manufacturing Systems were invented the Lites smashed the Machinery you know I don't know do you think like that or or or are you more like me personally I take it all seriously and just accept it for what it is an expert giving his expert opinions but I personally don't quite know what to do about it all myself anyway let's take a closer look by studying the transcript of the interview and I can comment and explain some language so we're going to go back up to the top of the the transcript now and I'm going to fly through it and focus on those highlighted bits of vocabulary okay and uh just focus on clarifying those things so the interviewer said I began by asking Jeffrey Hinton whether he thought the world is getting to grips with the issue of AI so if you get to grips with something it basically means you get it under control okay to get it under control for example I need to get to grips with this what would it be um I need to really I really need to get to grips so let's say uh someone has introduced a new computer system at work and you need to understand how it works and really get on top of it you you might say I need to I really need to get to grips with this new system I'm just going to spend a couple of hours this afternoon just working it out I really need to get to grips with it now you can imagine that this expression involves well it doesn't you just don't imagine it you can just remember that it involves the word grip which means to hold something in your hands without it slipping so if you hold something you get it under control right so that means getting to grips with something I'm trying to think of another example let's say you buy a new new laptop or you've got a new phone and you don't understand the operating system so you need to spend some time getting to grips with it meaning getting it all under control understanding how it works and being able to use it um mhm you get to grips with some homework that you've been given meaning you read the task and you try and understand what's what you've got to do you're you're preparing for the IELTS test you really need to get to grips with the test meaning understand how it works and get it all under your control in this case is the world getting to grips with the issue of AI are we getting it all under control do we understand it can we control it okay um and then we've got um and from your perspective from having worked at the top of this meaning the top of the artificial intelligence movement having developed some of the theories underpinning all of this explosion in AI so the theories underpinning the explosion in AI if something underpins something it basically kind of works as a foundation I guess this must come from like um the making clothes making clothing tailoring clothes that when you let's say if you're making a shirt you would use pins metal pins underneath parts of the shirt you underpin the shirt holding the different parts of the shirt in place before you then Stitch the shirt together so that's underpinning a shirt it's kind of like the the the the uh connections or the parts that hold the whole thing together MH um it's a bit like a foundation for a building so you have ideas underpin something for example what are the ideas and Concepts that underpin my approach to doing this podcast a lot of it's based on you know the the the training that I've received as an English teacher over the years so the idea that language should be presented in context but also stuff I've learned as a teacher that it helps when the language learning process is personalized both in the way that you consume language so it's easier to essentially acquire language when it's presented to you in a personal way rather than an impersonal way and plenty of other things as well these are ideas that underpin my approach to doing this podcast so when we talk about theories or ideas underpinning something it means the things that are that form the the the the underlying structure uh that defines the way that something works like the foundations of something okay um so the interviewee um developed some of the theories that underpin this explosion in AI okay so Jeffrey Hinton said some people think these things don't really understand meaning some people think that these AI systems don't really understand things they're that they're very different from us that they're using some statistical tricks so statistical refers to the word statistics statistics is basically like data either quantitative data just numbers or qualitative data more values uh you know different types of data information this is statistics right so some people believe that these AI systems are basically just using statistical tricks like for example maybe when they produce language that they are um just producing sentences based on like frequency for example well after this word the most common next word is this so that's I'll just add this that they're just using stati iCal tricks to perform uh these acts of intelligence but uh Jeffrey disagrees he thinks they're not just using tricks that there is actual processing going on that is very similar to the way that the human mind processes things which is really interesting again we're talking about science fiction because you think of films like uh Blade Runner and the whole idea of Blade Runner is do synthetic humans or Androids do they actually have emotions they are so similar to humans they even have memories which have been implanted right their emotions are just as powerful as the emotions that humans feel so what's the difference then really between a synthetic person who is experiencing emotions in the same way that a human does a synthetic person that is essentially thinking and operating exact the same way that a human does what's the difference between that and a human then really and don't those synthetics those uh replicants don't they have as a result somehow the same rights as humans in fact aren't they even more than human like there's that there's that famous speech at the end of Blade Runner where rutar Hower is saying to Harrison Ford's character I've seen things that you people could never understand I have insights about the universe that you couldn't comprehend I am you know I'm more than a human I'm uh greater than a human I am more human than human um just an interesting idea that maybe these AIS um maybe they they they should have rights which is again a terrifying thought because if any of you have seen the animatrix which is the animated there was an animated series of short films based in The Matrix universe and one of the stories in the animatrix talks about how the war between the machines and the humans happened and a principle key moment in it is a legal case where it's decided in the courts that artificial intelligences don't have the same rights as humans and this was an important uh groundbreaking case in law that stated that these these intelligences don't have the same kinds of rights as humans and this was the basis upon which the AI felt there was an injustice and that was like the the start of a big conflict and ultimately led to a horrific war between the humans and the uh the the AI which the AI won um so should AI be considered similar to humans how do you make the distin ultimately when they think just like us they you know anyway it's a philosophical question that but anyway um Jeffrey says that they are so people think that these systems don't really think they don't really understand things they just use statistical tricks but he's arguing that their s their intelligence is far more sophisticated and humanlike than than we realize um the interviewer said what is it that's triggered your concern I've already used the word triggered in this episode to be triggered on the Internet is when you see something or read something that makes you angry you know and it's often something that sort of angers you on a political level or maybe you get offended by something right so that's the that's one use of the word triggered but really triggered just means to trigger something is just to cause something to happen like in gun right in the gun you've got the barrel of the gun where the bullet goes down you got the handle which you hold in your hand and then there's the trigger which is the thing that your finger pulls which causes this the mechanism to fire the bullet from the gun right so that's to trigger the gun a trigger essentially then is a button that causes a reaction and in in this case as a verb to trigger something is exactly that to cause something to happen happen right so in this case what's triggered your concern meaning what has caused you to be concerned like this so you can imagine the the finger pulling the trigger and the trig the the let's say the the trigger triggers the the mechanism of the gun also something might trigger Jeffrey to have these concerns what was it that triggered his concern it was a combination of two things playing with uh GP pt4 chat Bots and also something else um understanding the way in which these things are a superior form of intelligence understanding the way that um these AI systems are essentially multi- neural networks something like that so when he got a more profound understanding of the way that they work that's what triggered him to be concerned he said they're clearly very competent if some or someone is competent it means they are capable of doing things they're good at doing things so for example if you are running a business you want staff who are competent meaning staff who can do things and they can do things well what do you think of um Sarah I think she's very competent I think that you know she's definitely one of the staff members that we need to hold on to I think she's a very competent uh teacher she's very good at problem solving she lesons plans very carefully I've observed her in lessons a few times and she's a very competent teacher she knows her grammar she's able to manage the classes very effectively very competent what do you think of Bill well bill on the other hand is uh different story first of all he's always late secondly I observed him last week and I watched him spelling on the board and his spelling is atrocious he can't spell he doesn't know the grammar he uh doesn't really seem to care about the students and in fact doesn't show any signs of actually knowing what he's doing at all he's completely rubbish he's a useless teacher he's I would say completely incompetent he can't use the photocopier he doesn't know how to say good morning he rarely dresses appropriately for the job um he's a slob he's rude he's lazy and he's frequently absent uh so he's perhaps one of the most incompetent teachers I've ever met so I think that we should probably so what do you think we should probably I think we should keep bill because he's a man what this situation became suddenly uh very sexist just just a little uh example of what happens in the patriarchal workplace anyway anyway obviously Sarah would be the competent one she would be the one that you would keep and Bill sounds like a total disaster and he you know you've got to let him go haven't you because he seems incompetent Jeffrey was saying that this the AI systems are clearly very competent they're very very good at what they do um so he he talks about making many copies of the same neural network so neural refers to um the uh systems in the brain right the connections in the brain um a brain like a neural network is essentially a brain right a system of connections um and he's saying that one of the reasons why AI is more sophisticated um and advanced than humans is because the difference is that humans each individual human has a a neural network meaning a brain right and the fact is that these these brains are not connected um and we we actually find it very difficult to share the knowledge we have in our brains we have all these complex difficulties with social communication and it's all a very inefficient system you know humans have to go to university to learn and they take three years to learn about just one subject but what Jeffrey is saying that these things are a su a superior form of intelligence because you can make many copies of the same neural network each copy can look at a different bit of data and then they can all share what they've learned so you get 10,000 people studying 10,000 subjects okay they all go off and learn this stuff very very quickly and then you can actually bring all these people together all these neural networks you can connect them all together and they instantly share everything that they've known that they've learned and then each individual person in that group of 10,000 knows 10,000 people's worth of information okay so that's what that's why he was saying that they are superior because they can you can make many copies of the same neural network essentially they they can share information with each other much more efficiently and effectively than humans can um so the interviewer says the key concern here is that it could exceed human intelligence and Jeffrey says indeed massively exceed so we've said we've we've we've had exceed before right meaning become bigger right um and massively exceed so this means become much much bigger right he then says very few of the experts are in doubt about that very few of the experts are in doubt about that if you are in doubt about something it means you're not sure about it right I'm in doubt about it experts are in doubt about that very few of the experts are in doubt about that meaning most of them are sure about it most of them agree with each other and they're and they're sure that uh AI will massively s massively exceed human intelligence um all right um Jeffrey went on to say that um some people believe that uh AI will be subservient to us that we'll give them the goals it'll be no problem they'll do what we say they'll be subservient to us if someone is subservient to someone else essentially they they uh take a um like a a lower position and they allow their masters to tell them what to do so a servant a servant uh takes a subservient position to his or her master right for example you can say make me a cup of tea and they'll say certainly sir would you like Two Sugars as usual you know and they take a subservient position they'll be subservient to us right uh in in uh a lot of cultures and traditionally women are subservient to men right in relationships and things like that uh not so much the case you know in in in many societies right but anyway just explaining the word so to so many people think that AIS will be subservient to us but then there are other experts who think that they will definitely take control and then he says given this big spectrum of opinions so given is quite a nice word we use it at the beginning of s es given this big spectrum of opinions I think it's wise to be cautious um so given is a bit like saying because there are or because of this right taking this into account given this big spectrum of opinions I think it's wise to be cautious think of some other examples of given you might say given that and then a clause give given that uh the sun is shining today I think a t-shirt would be sufficient um given the sunshine I think a t-shirt would be sufficient all right um given this big spectrum of opinions I think it's wise to be cautious because we have because there are yeah let's see if I can get a better explanation of that here's a bit more information about it so given taking something into account or considering a particular factor for example given the circumstances I think we made the right decision so taking into account the circumstances right because of or because we have because of the circumstances or thinking about the circumstances because the circumstances are the way they are I think we made the right decision so this word is often used to introduce conditions or facts that influence a conclusion or or or decision given the nature of the situation I think we need to be careful it's like saying because the nature of the situation is difficult I think we need to be careful given this so it could be given plus a noun like given this big spectrum of opinions or given plus a cause with that given that there are many different opinions I think it's wise to be cautious so anyway he's saying that because there are lots of different opinions there's a big spectrum of opinions a wide variety of opinions he said I think it's wise to be cautious so we've got opinions that say it'll be fine they'll do what we tell them to do they'll just be subservient to us and then there are other opinions on the other side that say no actually they will definitely try to take control and so considering we've got this wide spectrum it's probably a good idea to be cautious because we've got at least I don't know what is it 15 to 50% of opinion saying that but this could be very dangerous so it's probably a good idea to be cautious uh the interviewer says could they not be contained in certain areas like scientific research so to be contained meaning limited kept in one space like for example you know animals in the zoo a lion is contained within its cage sadly right to be contained meaning kept in one area so could AI not be contained in certain areas like scientific research meaning could we not just restrict its use to certain areas but not for example the Armed Forces so if we could just limit it to scientific use but not allow it to be used in military situations the Armed Forces this means the Army basically the Army the Navy okay the Air Force these are the armed forces and Jeffrey said maybe but actually if you look at all the current legislation it's a legislation means laws so we've had regulations laws legislation they're all kind of the same thing right regulations are laws which seek to try to control things and they're often made by governments or something like the European Union which issues regulations as a way of like you know um creating Frameworks legal Frameworks to control things tax regulations and so on legislation means means law specifically means laws if you look at all the current legislation which is uncountable law laws that's countable that's plural so if you look at the current laws or in general the current legislation including the European legislation there's a little clause in all of it that says that none of this applies to military applications a little Clause a clause is a line in a legal document in an agreement in a contract or in a piece of legislation a single line which might uh provide a right or take a right away or you know allow something to be possible or not allowed so a clause so when you're reading a contract you've got to read every single Clause you might find like 14.13 says you know these uh regulations are not limited to the use of military uh interventions you know it might say uh AI must be contained within these limitations blah blah blah Clause 14. 1.3 except in the case of military applications which is a little clause which means that uh none of this applies to military applications or military uses the way that it applied to uh military situations uh Wars fighting the the actions of armed forces governments aren't willing to restrict their own uses of it they if governments aren't willing meaning they don't want to they are they just don't want to do it they're not willing to do it this is this word we use all the time in business situations when we're doing negotiations for example are you willing to would you be willing to provide a discount of 20% if we order uh you know over 3,000 units um we'd be willing to give a discount but I think 20% is a little bit more than we imagined would you be willing to go to 15% I think 15% is more realistic you know that kind of thing it's basically what what what do you want to do are you willing to do this are you willing to do that governments are not willing to we don't you know it's it's more appropriate language for this kind of subject saying willing to do this willing to do that or not willing to rather than saying want to you know we don't say governments don't want to restrict their uses of it we say governments aren't willing to restrict their own uses of it so it's a slightly more formal more serious way of essentially saying want to or don't want to willing to we also say governments aren't prepared to which is another way of saying that they they just don't want to um so governments aren't willing to restrict their own uses of it for defense restrict meaning limited moving on um the interviewer says uh that's happened since you started warning about AI is that the sort of pathway you're concerned about so the interviewer asks about the way things are going to go in the future he said is that the sort of pathway that you're concerned about I suppose this is fairly clear isn't it really you think of a pathway somewhere you would walk down for example a pathway that takes you down to the bottom of the Garden or a pathway that takes you through a field or something like that so a pathway is just a a way in which things can move so he's saying is that the sort of way that you're concerned about meaning the way that this could develop isn't that the kind of pathway the kind of road that you're concerned about and he said I mean it's the thin end of the wedge H this is quite a nice idiom the thin end of the wedge so a wedge would be a kind of um like a piece of wood okay that is is thin at one end and Thick at the other end typically we use a wedge to you stick a wedge under a door and the door can't close you sort of wedge a door open right so a wedge is a thing that's thin a piece of wood that's thin at one end and Thick at the other end so it's kind of like triangular slanted piece of wood that's a wedge and you'd stick a wedge under a door but now you know what a wedge is we talk about the thin end of the wedge it's a bit like the tip of the iceberg it's a similar expression the thin end of the wedge means you got a situation that's the wedge in this case and you've got at one end the thin end of the wedge and at the other end the thick end of the wedge so um so in talking about uh Artificial Intelligence being used used uh in military situations for example Weapons Systems that can Target many different uh targets all at the same time uh allowing um governments to send missiles out to lots of different targets all at the same time is that the kind of thing that you're worried about he said that's the thin end of the wedge meaning in terms of the the situation of AI controlling military technology that sort of example is just the thin end of the wedge meaning that's just the H the smaller um maybe less serious end of the situation and at the other end there is a much bigger um uh way of understanding it so that means that there could be much bigger uses of AI in Warfare it could be much more sophisticated it could be a much larger threat so you got the thin end of the wedge which is like some uses of AI in in conflicts and then you got the thick end of the wedge would be a much bigger much larger and much more sophisticated use of AI okay so the thin end of the wedge is a minor change that could lead to significant and undesirable consequences in the future okay so he's talking about a small thing that could become a big thing uh for example allowing this exception could be the thin end of the wedge for more serious abuses of power this idiom is often used in debates to warn that small actions or changes could escalate into bigger issues okay A bit like a slippery slope kind of situation so he's saying that this these these uses of AI are just like the small end and that ultimately they could become much bigger later on it's the thin end of the wedge um what I'm most concerned about is when these things can autonomously make the decision to kill people so we've talked about autonomously meaning that they do it on their own they do it automatically uh autonomously meaning on their own without being told to do it so robot soldiers says the interviewer and Jeffrey says yeah those or drones and the like so and the like means and things like that so the like means things like that so robot soldiers yes those or drones and the like or drones and things like that remember you can get a full list of all this vocabulary that I'm describing here on the PDF that I've mentioned already with definitions examples and comments as well in a long list so I do recommend that you get the the PDF it's completely free you don't need to give me your email address or anything like that you can just download it directly but it might be useful as a way of helping you to consolidate a lot of the vocab that I'm talking to you about here let's let's move on if we restrain ourselves from military use in the G7 Advance democracies what's going on in China what's going on in Russia shout out to my Chinese and Russian listeners who might feel a little bit triggered by this particular moment anyway if we restrain ourselves if you restrain yourself from doing something or you restrain yourself from something it means you hold yourself back and you're like no I won't do that I think I won't use AI in military applications so if we restrain ourselves what about our our uh competitors will they restrain themselves no they won't so that means we can't restrain ourselves from doing that um the interviewer said do you have any sense of whether the shackles are off in a place like Russia so shackles would be things would restrain you or restrain someone like um they are they are metal chains aren't they yeah yeah yeah yeah yes um a bit like when someone is in prison they might have um metal rings around their ankles attached to chains which are then attached to the wall these are shackles okay and these shackles with certainly restrain you from doing something so the the idiom the shackles are off means that we're talking about an unrestrained thing something that's unrestrained or where people are not holding themselves back so do you have any sense of whether the shackles are off in a place like Russia means do you think that in a place like Russia they are not restraining themselves and in fact they are really trying to um um develop uh AI systems especially for military applications and they are not holding themselves back they're not limiting themselves they're really trying to innovate in this in this area do you have any sense of whether the shackles are off meaning that they are not restraining themselves and he said well Putin said some years ago that whoever controls AI controls the world so I imagine they're working very hard so basically saying I expect the shackles are off yes the West is probably well ahead of them in research well ahead so they're ahead of them meaning they are in a um you know in a in a forward position the opposite of that would be they're behind them and well ahead of them well ahead of them meaning much further forward in research we're probably slightly ahead of China so we've got well ahead of them slightly ahead of them right um the interviewer says it sounds very theoretical this thread of argument that's just interest an interesting collocation we talk about a thread of argument or a kind of line of argument we actually say a line of inquiry series of questions a thread of argument is a series of statements that make up an argument a position so we talk about a thread of arguments quite neat phrase because a thread suggests a line you know again going back to making clothes making a shirt you use a thread you use a needle and thread to you know Stitch the parts of the clo the clothing together and you thread the needle through different parts of the clothes leaving this like you know quite a neat line that moves in and out so this is a thread of argument this sort of sophisticated way of putting ideas together to create an argument so it sounds theoretical this thread of argument but you really are quite worried about Extinction level events Extinction for the human race would mean where the human race gets wiped out and there are no humans left that sounds a little bit uh alarmist doesn't it um it's probably unlikely to result in extinction level events I would imagine I mean that's just speaking personally probably what would be more likely is that you'd end up with maybe a lot of a loss a large loss of human life like we've seen in the past in Global Wars but where maybe a a certain percentage of the human race would survive and that would probably be the Richer ones anyway um are you quite worried about extinction level events events at a level that could cause the extinction of the human race we talk about Extinction of animals the dinosaurs are extinct um an extinction level event for the dinosaurs was the impact of several um as asteroids that hit the earth causing all sorts of environmental uh you know challenges that most of the dinosaurs couldn't deal with and they became extinct okay um and Jeffrey said we should distinguish these different risks so distinguish something means make a difference between them we should distinguish these different risks show that this risk is different to this risk so he talks about the risk of using a for autonomous lethal weapons doesn't depend on AI being smarter than us so there's the use of AI for Weaponry by humans and then there's another risk which is that AI on its own Auto uh autonomously choosing to uh attack the human race so these are two different risks and he says that he's worried about both so the one risk is just humans using AI to kill kill other humans and the other one is like AI going rogue so he uses this expression the risk that AI itself will go Rogue and try to take over so to go Rogue means to kind of um H have you seen Mission Impossible the mission impossible films there's one called Rogue Nation right R Mission Impossible Rogue Nation also it makes me think of um cuz you know I I understand all issues through the context of Pop Culture uh movie plot lines um the born identity films with Matt Damon in that in those films he goes Rogue right so he was a spoiler alert he was a specially trained soldier uh but he goes Rogue meaning he goes off and starts making his own independent decisions right he no longer follows the orders or commands that he's been given he goes off and starts making his own decisions so he and he's no longer controlled or subservient to his former military bosses he goes Rogue same thing with Tom Cruz in some of those Mission Impossible films where he realizes that his bosses at the CIA have been compromised and they're now working for the enemy and he realizes that he has to just go Rogue he's going to have to go off on his own and make his own decisions and in fact his bosses his former bosses are trying to catch him right Ethan hund's gone Rogue and then he jumps off a building and breaks his ankle you know classic Tom Cruz stuff then he runs really fast in some situation um so he's wor uh Jeffrey is worried that uh AI will actually go Rogue and try to take over meaning to take control to take over to take take control of the world take over the world and so at this point before it's more intelligent than us we should be putting huge resources into seeing whether we're going to be able to control it so to put resources into something means to invest money to invest time to invest um um different things into um trying to understand if we can control it so we should be putting a lot resources into this putting a lot of people into working on it spending a lot of money on it resources means things that you can Ed to get something done it could be money it could be people it could be uh infrastructure whatever it is we should be putting these resources into understanding if we can control AI to prevent it from going rogue and trying to take over the world so basically we need to set up the Avengers and we need to do that really fast so if someone can call Tony Stark that would be that would be good he doesn't exist oh dear I don't know what we're going to do then um yes I'm very worried about AI taking over lots of mundane jobs mundane jobs are like boring jobs that you know people have to do but they don't really want to do like kind of data entry jobs I mean you might have a mundane job and sure it might be mundane it might be boring and always the same which is what mundane means but it might also be pretty important important for you maybe you don't enjoy your job but you need it in order to get your money to pay to pay the rent so he's saying I'm very worried about AI taking over lots of mundane jobs and he he does then say that should be a good thing meaning that humans don't need to do those boring tasks anymore it would be a good thing if the money could if the benefits of uh AI were spread equally but that's not the case in in our world as it is today that those people would lose their jobs and then the money would just go to the business owners or the the the rich people and the people who' lost their jobs would just lose out so it it wouldn't be a good thing in fact he said that AI replacing people's jobs is going to lead to a big increase in productivity so productivity means being able to do a lot of work producing or manufacturing a lot of products or at least uh being able to do a lot in terms of services work work related services so for me productivity means making podcast episodes and actually AI does help me with my productivity it has led to an increase in my productivity because it helps me to create lessons because it I use it as a way of generating English which I can then adapt and turn into podcast episodes umh okay so being being productive uh doing work so AI is going to lead to a big increase in productivity which leads to a big increase in wealth so if we talk about wealth we talk about uh money owning money being wealthy means being rich basically so uh an increase in wealth means uh more people having more money an increase in people being rich and if that wealth was equally distributed meaning if if everyone got an equal share if it was distributed if it was passed out given out into society if everyone got an equal amount that would be great but it's not going to be equally distributed because that's not the way the world works we are we have a very uh inequal system uh so it's going to increase the gap between rich and poor we've talked about that which increases the chances of right-wing populists so these are sort of political figures who are usually on the right-wing end of the spectrum who essentially use basic kind of human emotive reactionary opinions as a way of um manufacturing support for their own essentially corrupt and uh probably unethical and dangerous policies right that's what we mean by right-wing populists it's a it's a form of um manipulative politics that uses yeah um issues that cause people to have knee-jerk reactions for example the the the previous UK government spent a lot of their time and energy talking about how they were going to stop illegal immigration because this they worked out was the issue that a certain number of people in society were very emotionally invested in the idea of small boats arriving on the shores of the country every day and that it's illegal immigrants who are the cause of all of the problems in society not the fact that the government are giving all of the money to the their super rich friends it's the small groups of desperate people coming to the country to get help these are the ones who we need to focus our energy on and so they would spend massive amounts of time doing these performative acts of um uh like policymaking which wasn't even real policymaking just in order to get support so that they could guarantee that they keep power so that they could then just keep doing the things that they were doing often which were you know corrupt business dealings and other things of that nature populism okay so he's basically saying when you get a bigger gap between rich and poor you get more and more right-wing populists in power because essentially people the most people who are who are getting less feel disenfranchised they feel angry and then the politicians in power use that anger and direct it towards minority groups or other easy targets and it's all just an effort to whip up emotion which they can use to to maintain power so this is this this is obviously a very pessimistic view that uh with this that AI will allow uh the rich to get richer and it will allow them to manipulate the public more and more leading to a sort of controlled state which is also frightening to be fair the interviewer says so to be clear you think that the societal impacts from the changes in jobs so societal impacts I think you know what impacts are like strong effects what will be the impacts of this technology on society imp imps on society what kind of impacts societal impacts so societal is the adjective for society so you could say what will be the impacts on society or what will be the societal impacts can you say it what will be the societal impacts from the changes in jobs um these things could be so profound meaning so deep and so significant and so he so heavy uh we may need to rethink the politics of the benefit system to rethink meaning think about it again meaning find a new way of thinking about it to rethink it we need to rethink the politics of the benefit system the benefit system is a system that's in place that means that governments provide benefits to people in society who need help when we say benefits we mean things like um um child care benefit this is money to help families pay for food for their children or pay for child care um pensions are a form of benefits so this is old people who are too old to work and they're given a a they're given a pension which is a certain amount of money every month or every year to help them live um if you don't have a job you might have unemployment benefit of some kind which is money that you're given to support you while you find a job and so this is the benefit system it basically is there to support people who need support so maybe we need to rethink the benefit system and maybe we need to rethink inequality so this is basically look again at the inequality the lack of equality that we have and just think about a new way of of dealing with it and he says absolutely which leads us on to Universal basic income which I mentioned before this idea that um that every one could be given a basic income a basic amount of money every month which they could use to just you know pay for the basic requirements of Life as a way of preventing large um sections of society dropping into poverty and this is a this is a thing that people are talking about more and more and it could be a sort of solution to this huge inequality that we've got in society basically providing people with money it's quite a controversial one when you think about it cuz you know you just think what we're just going to give people money for doing nothing just to prevent them from falling into poverty and you know some people are of the opinion this is very bad thing to do that it encourages a culture of laziness and stuff like that and other people are saying well actually there's no other solution we have to essentially provide people with a basic living wage even if they they're not working because otherwise millions of people will live in poverty millions of people will starve to death because that's the situation we're living in so what do you want um that solves the problem of them starving meaning dying because they've got no food and not being able to pay the rent the rent is the money that you need to pay for your accommodation if you don't own your own house if you're renting an apartment you have to pay the rent every month to your landlord if you're a tenant so this could help PE prevent people from starving or prevent people from being being unable to pay the rent and if you can't pay the rent you will be evicted from your apartment and then you're on the street so without Universal basic income we could see people starving to death on the streets you know uh so so you know maybe Universal basic income is a thing that people that we need to uh set up in society so what you just you just try to the government needs to get involved right get involved if you're involved it means you are part of what is happening right you're implicated although implicated in English sounds like there's a negative uh uh sense to it if you're implic you you'd be implicated in a crime but no to be involved meaning to be part of what's happening the government needs to get involved means the government needs to step in and maybe try and control the situation somewhat by you know setting up Universal basic income and looking after people who need support uh Jeffrey says that's not really the way we do things in Britain we tend to stand back and let the economy decide a bit like in America they have slightly more of a small government approach certainly the kind of conservative model in the UK is that the we don't like a kind of big government Nanny State situation where the government is dictating what happens all the time there is a there is a a feeling in the UK that that's not preferable that we we prefer to let the economy decide the winners and the losers you know we have that more free market economy situation but um Jeffrey says I was consulted by people in Downing Street Downing Street this is where the prime minister is based so if you talk of Downing Street it's a bit like in America when they talk about the White House or Capitol Hill uh Downing Street is where the prime minister is so I was consulted by people in Downing Street means that people in the government asked for his advice he was consulted he worked as a consultant he was he gave his his advice um and he advised them that Universal basic income was a good idea but it's not a perfect idea because you can provide people with money that solves that problem but people don't have jobs just for money they also have jobs for a a sense of selfworth and give giv taking people's jobs away can also remove their sense of self-worth so we might be in a situation where people still need to do things um as a way of preventing them from just losing their sense of purpose um the interviewer said are you more certain that this is going to have to be addressed in the next 5 years so to address a problem is to a deal is to deal with a problem that this is going to have to be dealt with in the next 5 years this is going to have to be managed in the next 5 years it's going to have to be addressed in the next 5 years in the next Parliament perhaps that means in the next um in the next government so you got five years in the UK where the government has a period of 5 years and then after that there's a general election and the all the members of parliament get reelected or whatever and you get a different setup you get a different Parliament so he's saying that maybe this is going to be directly addressed in the next Parliament you know in about 5 years time maybe and he said uh probably between 5 and 20 years from now this will have to be addressed we will have to confront the problem of AI trying to take over to confront it means to come face to face with it and deal with this problem okay A bit like at school if you're getting bullied if there's a kid at school who's always teasing you stealing your pocket money hitting you around the back of the head and generally making your life a miser you might have to confront that bully stand up to them face them you know similarly between 5 and 20 years from now we will probably have to confront the problem of AI trying to take over it's so serious isn't it can't believe it really that relatively soon we're going to have to come face to face with the issue of AI trying to take over the world is it even real am I really talking about this I am actually um are you impressed by the efforts of governments to try to try and R this in to rain something in means to get something under control to get to grips with it rain re e i GN now this refers to horses rains are the leather straps that you Ed to hold onto a horse's head you hold the resins when you're riding a horse you hold the r in your hand and you can use it to turn the horse's head left and right and so on so to R something in is to get something under control a bit like when you um hold the resins of a horse so are you impressed by the efforts of governments to re this in are you impressed by the efforts of governments to try to get this under control and he gives his answer blah blah blah he says I'm unimpressed by the fact that most of the regulations have no teeth so he's talking about the fact that most of the laws relating to this uh just don't have any real power they have no teeth right they don't have any real power that's what that expression means do you think that the tech companies are letting down their guard if you let down your guard so in boxing right you hold up your hands you punch with with your fists but you've got to hold your guard up as well which is your other hand or even both your hands protecting your head or protecting your body this is your guard and if you let your guard down it means your hands go down and suddenly you don't have any defenses anymore and you can easily be punched by your opponent so do you think that the tech companies are letting down their guard on safety because they need to be the winner in this race for AI so basically our tech companies in their efforts to try to um be the win in this kind of arms race for AI are the tech companies not thinking about safety are they letting down their guard on safety meaning are they allowing AI to develop in dangerous ways because they're trying to race to become the leader in the in the marketplace and the answer is more or less yes it is um he said Google was concerned about its reputation meaning about what people thought of it and I think pretty much the answer was probably yes then the interviewer asks um Jeffrey for his comments on what jobs people should do what degrees they should do degrees means University qualifications Bachelor degrees master's degrees the interviewer says it it seems like the world is being thrown up thrown up in the air so if things are up in the air or if things are thrown up in the air it means they are sort of suddenly there's no Order anymore and uh we're not sure about anything everything's up in the air at the moment we can't be sure about anything so what would you advise somebody to study uh to to Surf this wave meaning the wave meaning the this trend in society to surf the wave is to get yourself in a position where you can actually get a beneficial situation to surf the wave so instead of being drowned by the wave you can somehow climb on top and you can ride along so basically what job should people do in order to find a good position in this situation and he said my best bet meaning my my best prediction my best um uh yeah my best prediction is that plumbing is is a good idea Plumbing I talked about it several times already notice there's a be in the middle but it's not Plumbing it's actually pronounced Plumbing so the B is silent so again you know working with water uh pipes and things just basic a basic mechanical job practical job because he said these things aren't yet very good at physical manipulation meaning AI systems are not very good at the actual physical side of things so we've seen those robots those Boston Dynamics robots that are able to kind of rather clumsily open and close doors they can maybe draw with a pen but they they don't have the sort of physical dexterity that most humans have with our ability to use our fingers and thumbs and arms and stuff so when it comes to actually uh fixing fixing a leak in someone's kitchen a human being is still much better at being able to sque open up the doors of the cupboard look inside work out what the problem is and then get into a position where you can open up the pipe and fix it and stuff like that so we're still better in terms of physical manipulation so something like Plumbing is a would be a good career uh driving says the interviewer and Jeffrey says no driving is hopeless meaning there's there's no hope in terms of driving so a career in driving is there's no future in that because you know we're going to get driverless cars it's taking time but we will get them he even says journalism might last a bit longer but I think these things are going to be pretty good journalists quite soon and probably quite good interviewers too and that's where the interviewer decides to end the end the interview when he says oh yeah they'll be better at interviewing than you and the interview goes uh okay well that's the end of this interview thank you very much for your time you're welcome so what do you think I'm going to ask you at the end here to tell me what you think about all this so leave your comments in the comments section I'm curious to know what what your reactions are to all of this here's what I think so personally I think this I think we would be wise to take these comments very seriously although as as I said uh I don't know what to do um I don't know what to do about it I mean what should we do us normal people I have no idea um I think there's no doubt that as AI develops it will make many of us redundant meaning our jobs will disappear so God knows what the world is going to look like just for that reason alone people often say that AI won't completely replace a lot of jobs because people like the human factor but I'm not completely sure but you can tell me you know would you choose me a human as your English teacher over uh a a very effective AI teacher would you choose me simply because you like the fact I'm a human even though arguably I might be less efficient and more prone to human error than uh some amazing AI language teacher that could look and sound just like me does it matter that it would look like me I don't know uh when AI gets to a certain point it will be extremely good at being human enough to make it satisfying for us to interact with them at the moment AI Bots and I'm talking about ones that look like humans so you could have an actual like video conversation with it where you can see its face and its lips moving and its body language at the moment it's not very satisfying to have conversations with that kind of thing thing uh it's not bad it's certainly a lot better better than it was but they still are not very convincing and it's generally kind of awkward it's not so bad having a conversation with chat GPT for example where it doesn't have a face it's just a voice replying to you that's actually surprisingly amazing but in terms of like replicating a video call with an English teacher it's not there yet so but when it does get to that point and that will be rapid eventually we'll probably be able to have essentially like video calls Skype calls or Zoom calls with an AI human and it will be really difficult to tell that it's fake so we'll get there um I think people will quite gladly switch to AI versions of many things because the quality and the naturalness will be exceptional it's going to be insane um I mean that raises all sorts of other questions about fake news and stuff of course as well right how will you know what real what is real anymore which again goes back to that idea of the kind of um the the the potential for U propaganda and government level control where it'll be quite possible where the Matrix will sort of come true where eventually uh the powers that B maybe I'm being very paranoid but I don't know the powers that be will be able to essentially just create a completely simulated world for us I mean that that's already happening of course with the way that information is controlled it's all it's it's happened for for centuries of course but with the internet with so different forms of social media with the way that the government um you know um monitors regulates controls the media that we see it essentially defines our reality you know and all you need to do is just you know have a look at the state controlled media and the narrative that it presents and you'll see that you know they are definitely controlling your reality and when you look at well anyway I won't go on um but anyway um so it raises questions about about that but also basically when these simulated conversations with a human become really natural I think sure people will just switch to them they'll have no problem with it um AI will be absolutely Central to everything we do entertainment for example we'll be able to create our own movies instantly choosing all the factors we want for example which actors the themes of the movie The style the storyline type anything and generative AI will create it instantly it'll create our Perfect movie and we can just sit down and watch it and it'll be good we'll be able to do the same thing with music we'll be able to say you know hey whatever you know you'll just talk to your AI and say make a playlist of songs that are upbeat kind of sound like a bit like the bols but with a modern Vibe and it'll just do it make all the songs about um learning English and it'll do it and they'll be good A lot of the things will be automatic right a lot of things obviously driving but so many other things will just be automatic and AI will understand what we want and we'll make it happen one day we will look back in horror and amazement at the way that we live now for example driving we will look back in horror and amazement that we actually let humans drive cars on highways we will think this is madness we'll think wait we let humans drive cars six line High six Lane highways driving 80 km an hour in opposite directions right next to each other and this was normal and people did it every day and people died on the roads all the time absolutely insane we will think of it think it is Bonkers um English teachers chat GPT is already stunningly reactive well-informed and capable as a conversation partner AI will be able to make strategic decisions for most things that are based on much better clearer and efficient thinking processes and will probably produce better results more quickly and efficiently than humans AI will understand us better than we understand ourselves and might be able to completely manipulate us think of advertising which is so incisive and effective that it's basically hypnosis or mind control and hypnotic mind control is definitely a real thing that is practiced in various entertainment situations but also in Military and secret service projects so AI will probably be able to brainwash us extremely effectively I am worried about what humans will do to other humans using AI as a tool who will control it what will they choose to do with it but you know I don't mean to be just completely pessimistic AI is also awesome what it can do is incredible and it could be tremendously empowering uh you know in medical situations we could use AI to help diagnose uh medical conditions and to provide medical care in the most adaptive way um I already use AI a lot in my job as I said earlier but it will develop to unbelievably sophisticated levels in ways that we can't quite comprehend now but AI is far from being this is this is maybe the most negative point in the whole episode I'm so sorry everyone AI is far from being the biggest threat to human existence at the moment it might even be our savior in fact and that bigger threat is of course the climate catastrophe which is another story for another time now I want to explore this subject further but I think it's that that's for another episode um I'm interested in making projections and predictions for how specifically AI could change our society over the next 5 10 20 50 years I think it's fascinating so what do you think does that sound interesting let me know and perhaps I can explore it in another episode but in the meantime leave your comments uh below perhaps with your own opinion here are some questions for you to consider are you optimistic or pessimistic about this or some kind of combination of the two do you use AI at the moment how do you use it could AI be a threat to your job one day or will it open new possibilities and new opportunities for your work do you use AI to help you learn English and will English teachers all be out of a job in the next few years would you choose me over my AI alternative there's a question anyway thank you so much for listening if you look at the PDF you'll see a full vot vocabulary list of all the highlighted bits of vocab in a list and also another list with loads of um uh all of that those bits of vocab with definitions examples and commentary so tons more detail on the PDF which you can just download just freely from the episode show notes but that's it that's the end of this episode thank you so much for watching or listening quite I just dumped all sorts of heavy things on on your mind for this one I hope I didn't bring down your mood at all I mean it's it's kind of terrifying but I mean I feel actually quite energized by the subject I find it fascinating and quite stimulating but I'm curious to know what you think about it all thank you very much for watching thank you for listening speak to you in the next episode of Luke's English podcast but for now it's just time to say goodbye bye Bo Bo Bo\n"
     ]
    }
   ],
   "source": [
    "video_id = \"4YgV55DZPQ0\"   # only the ID of YT video is used\n",
    "\n",
    "try:\n",
    "    api = YouTubeTranscriptApi()\n",
    "    transcript_list = api.list(video_id)\n",
    "\n",
    "    try:\n",
    "        transcript = transcript_list.find_transcript(['en']).fetch()\n",
    "    except:\n",
    "        transcript = list(transcript_list)[0].fetch()\n",
    "\n",
    "    transcript_text = \" \".join(chunk.text for chunk in transcript)\n",
    "    print(transcript_text)\n",
    "\n",
    "except TranscriptsDisabled:\n",
    "    print(\"No captions available for this video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBIcmI6bA0qq",
    "outputId": "0f81b531-224f-477f-c6ab-0dc74920e792"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<youtube_transcript_api._transcripts.TranscriptList at 0x7fcd453a1a90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwITdNssLxwM"
   },
   "source": [
    "#Step1(b): Indexing:(Text Splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rBJpUXhmIc2D"
   },
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.create_documents([transcript_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6C4GWMQqMIQv",
    "outputId": "2cdc1e98-81b3-4eb6-8f86-48711e0d196a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IESUiIBoMueG",
    "outputId": "3eb0b8fe-6d0f-4601-c69b-c67a0618d184"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"statistics is basically like data either quantitative data just numbers or qualitative data more values uh you know different types of data information this is statistics right so some people believe that these AI systems are basically just using statistical tricks like for example maybe when they produce language that they are um just producing sentences based on like frequency for example well after this word the most common next word is this so that's I'll just add this that they're just using stati iCal tricks to perform uh these acts of intelligence but uh Jeffrey disagrees he thinks they're not just using tricks that there is actual processing going on that is very similar to the way that the human mind processes things which is really interesting again we're talking about science fiction because you think of films like uh Blade Runner and the whole idea of Blade Runner is do synthetic humans or Androids do they actually have emotions they are so similar to humans they even have\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Mq23lLLNDp-"
   },
   "source": [
    "#Step 1(c) & 1(d) - Indexing (Embedding Generation and Storing in Vector Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528,
     "referenced_widgets": [
      "cae2595d107c4a49839e72f166ee0ebc",
      "5f3343e4cbc344d6ab8222f00cd29a11",
      "0766c2c1196045ce96918b756d791e3f",
      "d5e6128c9b0c4c278f0d082831a600e1",
      "ecc69603dd044cedadea9890e1541d25",
      "52eabf2bf4e240f18604993b1d65d1ac",
      "ab38b61b05eb4df4ad2e39b0f2b51c5d",
      "a91d2d5e69b643289f43999a881db991",
      "a82ef7dda46f47a6b44c28e6dab3f1f4",
      "5302465774d645379e557f11af4b2a9e",
      "8305547c03694c69a961eadd7d9adedd",
      "0a226748034847d8a6119a1b37a340c4",
      "e968367376754d6aa12c56cc8a68f3c3",
      "7b41ff395f694c20ab35f7f8cd12dc2b",
      "118262ec48b04f3b825bed2fcb270ebd",
      "050017c80c614de384b6ba890622792f",
      "d49a7080161c4250896e36cab009e79a",
      "4b739810189c4143918b5bc91d886c89",
      "2cf5db184e1c4acaae6686f7dc1877d1",
      "e00477cdcd8f4e1bba923ecdbc617437",
      "fdec6fd4d4fe4411920d6c157d77e5c1",
      "75888c4967144b77ab43129e8e1cb078",
      "9e57c605ecf844dda98945e508ab4c93",
      "00e4eaf511484d6d8bca04176e356461",
      "ff76252cc3b343018727d70acfa054b7",
      "a10c1c71f52a4b629e01f84d31c61275",
      "babb732e504f484984ec572c3077c0bb",
      "2a7bbe28daae49b59b7c0a91cfba3570",
      "57078b713ffc4fa5a16b10ba136f3246",
      "7709c81838a2408599163d3c18fc15fa",
      "005a41d9755f4ed782461c73c781df5b",
      "745479636e734832bb4570d490c0c4b1",
      "8338780cd8014f69830c92b313fcf46f",
      "034a38b806484216a48b61fa83973816",
      "8c74710704e24032a2d0f06c262dab87",
      "9542511ad8a14ff9b063a518d137e0b8",
      "0e357c4b3fe24710b3efd260cbed1e7b",
      "4b2f77ae116d4c208b4d9c0dc0d2bea6",
      "34577aeda8a241a7bbfa7ed88f7e58ba",
      "27e33c26e8214878a1d23a36e15835d0",
      "3f8249bb30234d849c1195131473f690",
      "0385a958e78c495f9a6c3221eb38b651",
      "53e52d1bc89f42c09258cae8570cdaba",
      "9b9cf5ca32ee4e50918ac3f4cef897c2",
      "1798fc2ccfc6454db70fbaa7166fb5f4",
      "44afff3f05494a9f8a359c317269a22d",
      "ddbec1b856e04602850c410f2fa25ec5",
      "5b47ba6b92124868ba6948bc463cd8c6",
      "303a7d54f8c74b0e9f4df7a11112bc91",
      "32f1cf687c1141f0ad2365e8e63f0fbd",
      "37c1f9e5b04b43878d878f2cfbeb32b3",
      "207525b78a014fd686f9208e33060dc8",
      "92776ae59853432596eca22ffbf30ec7",
      "93377e41be6e42fc9e1d3dd10b6ddbf6",
      "ab220d6c1dba421db7984b647759c595",
      "02ef9ac80b2f4279926de051619a669e",
      "b9f2aae718dd4c58acab147d873303a4",
      "69a2f0003cfe4fd788e70f7ab7a2eeda",
      "8ee1101e3a9b4bf3b2d3a0645822ba07",
      "1742797a89e34f93b5ddc73157f3c8be",
      "a4042ccdd2124dab8bad7fd90165d6d1",
      "37b67c20617649a0ab881414a0ba3b33",
      "21b48c21c0044e68a322d82c81e51c45",
      "a11637d464334344a19a1ac2439e33be",
      "84aa7aff1d94454db0b8128f5db0dae7",
      "608e1e87f02d430bb201094c2dbd34bb",
      "0566bc61939045fcb9008405dad667dc",
      "d0d134a88b3549ce8fc3805fa2cb214b",
      "012540122b124846a61c9674e0ae9492",
      "df643f4536d54e0c888d2989d6f771b9",
      "478315bd9fe44fcabf82d2ba89ff551a",
      "73a989118cfd406ba8c9c679f66be139",
      "ced41e52a9174c9ea35606ef02b10b18",
      "a3b68983bae843e89929b5751be8b5d5",
      "ba4e7df819f243b5aa4a21b141ccdf92",
      "cdc77cbbefd54d8aa6efb8c8f516b5bb",
      "378f9c6b2a244c5ebfdd626791c8a9da",
      "aea1696455a94fcbb1e116ea22c573c8",
      "6b507596eaea4ae9a01ab0ef02c0b898",
      "0a579ab015644e9e8e354335bc7b7b3b",
      "9eb00d79410749d39d08286cf938d2e5",
      "a5202139449d4d7698dfa7eb3ea40d15",
      "264552e5cdc14fbcb2a70b9a5eb75800",
      "5dbafced30864f738cf6680c97670b06",
      "617b3675d8a34c089836c81c326796a2",
      "b7d6d3c57dea4fbe8a6fbd3f67e7b5e1",
      "6cda5197b8d14cca8b450d6210cf3845",
      "b63e934b06d3496ebb3dbcd682e72c07",
      "578fa13bca8a4cee97751ab5c4830a6d",
      "133821228aea4e57b1a725211decbe82",
      "0d40236e05cc4862a8915f27a0e1b961",
      "cc29a8ca43dc4fcdbea3514ce5b3a6a6",
      "ce19296e28bf42fab2f02241d39c3aca",
      "e783ffcc6db14045882cd28502292cca",
      "25fc5842814846a8a468a8fe4fc88852",
      "0c6c93fda11849fd860ffc6227ffe444",
      "ded200e0a88c4e1f85a73c858f4e7807",
      "8626a790e97f4a379b233aa821944c09",
      "9a3fa243ed1d4279898fc3f5e7b01d9a",
      "29b5b6ef155a4a2d922c126e302c4a74",
      "e6c67bfb2e734347a3b8d9297935cb55",
      "67e4b97561fd433f889e4f890327fff5",
      "5cae764abc1c420eaf9226340aaa3ffd",
      "2cfeedeb8c9047c3928d8a146e07aca8",
      "11b40f9c67a34050b1ddc81318378e74",
      "143ffa8a617c4e05b85be28215234f65",
      "4ac802bcb4234d1181e26a0d076fa66f",
      "4d1250ccf478403c88b7f6a1b8d2cb27",
      "b40a76b8388049e4ac49dd932a9e6d53",
      "7eed63218357487eb8a91f04c8e1a457",
      "39e3a1e91e2049caa0028647ef15d170",
      "29f97511565844c9b399364d046827ba",
      "5ddc41991e124927a621e8d75c6af9a8",
      "59efde1d191e45e0a5e1162c2f602635",
      "b83cfb1e640a451ca1bcbe1f656530e3",
      "afb5f7b9a6ca4a90a0d608f9cc1fbe2e",
      "cc50a845fbbe4317855999bc8c0c5f5e",
      "95c2a73628144576bc49da52608cb62e",
      "b6ef360751df487a9feace07a4b327b1",
      "416495d34c384b95969dfd588465b8cd",
      "e24258fe095f4dff8dc5c01c2fc65f77"
     ]
    },
    "id": "6GWwNNVaM2iQ",
    "outputId": "0c96945f-da44-4019-ba17-c7176b7f1b72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-334204816.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae2595d107c4a49839e72f166ee0ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a226748034847d8a6119a1b37a340c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e57c605ecf844dda98945e508ab4c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034a38b806484216a48b61fa83973816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1798fc2ccfc6454db70fbaa7166fb5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ef9ac80b2f4279926de051619a669e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0566bc61939045fcb9008405dad667dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea1696455a94fcbb1e116ea22c573c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578fa13bca8a4cee97751ab5c4830a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b5b6ef155a4a2d922c126e302c4a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e3a1e91e2049caa0028647ef15d170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QU3YxE7NRCk",
    "outputId": "2b231335-a122-49f4-e5ef-14baf4ada3cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '6db8e526-a436-4c3c-81be-5b47e24324b1',\n",
       " 1: '5f8efb37-d8ec-4ee6-9b5d-0cb88d6d9b42',\n",
       " 2: 'b0f453ff-25ff-48f2-99cc-7f2b8c648a1e',\n",
       " 3: 'a5e59954-5916-4a75-8fa7-556dd49ce422',\n",
       " 4: 'fe522a01-f575-4ec9-a5bc-2543de05b66c',\n",
       " 5: '76195ffd-a462-4004-90c8-d1f63fba4cad',\n",
       " 6: 'f18534e3-4aa8-4703-8c75-396b2764f3c8',\n",
       " 7: 'b3ad8f89-57b8-4bd9-8500-993e9070f688',\n",
       " 8: '122b3f0f-586f-4815-af72-a42dc0639bb9',\n",
       " 9: '48afc2c6-008e-4c69-b666-cad899731eb9',\n",
       " 10: '710634ab-5d61-4297-94fc-2a7bd9cd2bd2',\n",
       " 11: '485a1425-e234-4f87-9861-d89ba580dd2c',\n",
       " 12: 'e47f30d2-4c90-426b-b0bf-6e986bd53076',\n",
       " 13: '8cdac379-dc58-4b01-bd73-104ac82696a9',\n",
       " 14: '08170f49-6f2b-4133-a475-58ec3b72f2e0',\n",
       " 15: '09dcddc1-7105-4661-9ee9-9339abcf4574',\n",
       " 16: '843254f6-d5c1-49c1-9803-b9bd633587b0',\n",
       " 17: '8094520f-d371-4244-ac95-acfee3cd7488',\n",
       " 18: '546b1c9f-ad9a-4438-9737-168f89079681',\n",
       " 19: '1bde78fe-16f3-4d70-94ab-7c54749d931a',\n",
       " 20: '551847d7-3836-4774-98f8-f863d3341159',\n",
       " 21: '3ea2051f-5caf-49d1-9d9b-38ae54c85532',\n",
       " 22: 'd9d6bcb6-047a-4c4c-8e00-4ea8f7449b8a',\n",
       " 23: '625b839e-4754-472b-b609-049cc0cd7764',\n",
       " 24: 'c9986f37-b98c-4c8e-97cf-d365ef24f934',\n",
       " 25: '52a23ac4-947a-4e09-a806-97ff29e6e2f9',\n",
       " 26: '748f7227-6965-4279-8d25-438764223d85',\n",
       " 27: '00a2f496-96d0-4679-8feb-2142ed56c943',\n",
       " 28: '6cfc44f5-a2e6-4984-b4c2-bc3f3097f8ef',\n",
       " 29: 'a824f525-1b47-4726-a262-41429fe324e5',\n",
       " 30: 'dacea8ed-894c-4449-a018-349ccf4b5793',\n",
       " 31: '3cf4baa1-1138-4a64-aaf5-5697a46da362',\n",
       " 32: 'b7fea0ac-f286-4863-918d-47438ae7a360',\n",
       " 33: 'fbb13cf8-05a3-4bbd-a908-628e2e5bb7cf',\n",
       " 34: '52139f33-da0a-4fb7-a7cf-0302226f471b',\n",
       " 35: '27106de8-1e6b-4af1-b674-744272ff6c25',\n",
       " 36: '6ff3138d-0f16-48fd-ba4b-567faef6ffe8',\n",
       " 37: '3d9a76b9-4ae3-4ba5-b593-19253b353310',\n",
       " 38: 'c809f3e3-3c62-48b4-b309-6ece27cb75af',\n",
       " 39: '6b107d72-f5d1-4164-a72c-dcc88a433b0c',\n",
       " 40: 'c52e5b0d-a39b-4546-9edc-afc13e1fd63d',\n",
       " 41: '41864886-9cc3-4ae0-8e48-e2eebf36df25',\n",
       " 42: '8ad98f9f-f9a9-48d6-a1b9-cbd4475e1153',\n",
       " 43: 'dbc72816-a81c-468e-8a7a-19daa492a113',\n",
       " 44: 'c3f37f93-dfbb-4c1c-a083-488b6c5eba1b',\n",
       " 45: 'f78c4e2b-e0ba-4074-a46c-981dd1be3734',\n",
       " 46: 'bf5bdaa3-8fb1-4ed1-9903-0d82a6181338',\n",
       " 47: '05dfef1d-57d0-4543-8836-74c826e577dd',\n",
       " 48: '64cd7b10-740b-4fdb-8402-b4468a9dfba2',\n",
       " 49: '3f060748-0c35-4b47-9172-229cede22f01',\n",
       " 50: '92fbf34b-34eb-4122-be90-facb81714db3',\n",
       " 51: '5123885a-8314-4a8e-91f0-e7b89e2e4bec',\n",
       " 52: 'ed8b7b64-f407-44e1-92d8-102bba91262a',\n",
       " 53: '5ecd4fdb-372e-458d-9999-0cec3c474cff',\n",
       " 54: 'c383a137-1cd7-4545-8efa-4636d3de9532',\n",
       " 55: '85b0c0e6-ec13-4e3e-b6df-96d907c66f64',\n",
       " 56: 'ec7ad18c-cbe3-4501-9c71-8756504acd8d',\n",
       " 57: '53d7205a-e7c0-45ea-92d1-6c60e6b01c51',\n",
       " 58: '50da4d40-6c40-471e-8579-0d71e903ab84',\n",
       " 59: '10a4c5a7-3b0d-4891-88cc-93e493d217c2',\n",
       " 60: '602c4bba-6df0-47fc-bb08-9959eadb2e72',\n",
       " 61: 'e34adbd1-b7b9-4444-ba6b-e46c444b16b7',\n",
       " 62: '0827a30a-dedb-4921-b069-af192be02ca2',\n",
       " 63: 'd236f3e0-07bb-412a-90df-2da22461e592',\n",
       " 64: 'ced3c74a-5380-4282-bd28-bc47f0dc4e5c',\n",
       " 65: 'adb70602-7500-4e3f-b142-8ca2f3be8b25',\n",
       " 66: 'cb23821b-322d-4117-9cfb-e3c02771a081',\n",
       " 67: '6b4e9073-c7d5-4b2c-93ac-eb58aa5f02be',\n",
       " 68: '5107b33f-d19c-420f-8e66-e80d5bf94d90',\n",
       " 69: '9a8588b8-944b-4ce4-ab50-a582820f2552',\n",
       " 70: 'bdce591d-c7db-45a2-8c56-9682026c1833',\n",
       " 71: '30a8c919-a01e-4188-9393-c2d902f78e42',\n",
       " 72: 'f443823f-34e4-4acf-9d2a-8d902fe01ff8',\n",
       " 73: '826ae146-715d-4936-ae3e-44e783782577',\n",
       " 74: 'f63a9ed5-1348-4074-b3fc-a488f17a6ed3',\n",
       " 75: 'b05ed883-3f16-4cc1-b2b4-6ce481f9cdef',\n",
       " 76: 'f34f72c5-9eb3-4176-bf5e-2b83dfbdcdf2',\n",
       " 77: 'a858304f-35de-4a76-ac07-7c6bc96f934b',\n",
       " 78: '42eda19a-6e0f-4c4e-876d-18e209be6b8f',\n",
       " 79: '2ad5ef0f-1c9e-438c-afec-958bb3b5f7d0',\n",
       " 80: '01e24df7-80e6-43b0-8333-7b45fc3b5740',\n",
       " 81: '3985971f-44b3-4cf8-a64d-baab4b1cf6b5',\n",
       " 82: '56b4d2db-390f-4a46-813a-737ddb86510f',\n",
       " 83: 'd483811b-23b3-42b9-8a66-23a461e04bd3',\n",
       " 84: '464a9d83-5ee6-471f-934f-cc3de1383e24',\n",
       " 85: '4f285562-3792-4910-aa59-bc1a5cfea855',\n",
       " 86: '60eb014a-afc9-4766-870f-62594bbcfad7',\n",
       " 87: 'ff4644da-ffde-4a9c-83fe-b034e9c93993',\n",
       " 88: '1e5e07b7-ba39-4a5a-ba55-656fc094cda8',\n",
       " 89: 'f74e91f4-3d97-4987-9021-731bb90ea077',\n",
       " 90: '04022d4f-cba5-4f18-8209-ace5691c60ef',\n",
       " 91: '5dc3cf45-a46d-45d6-ace6-c70d76a23ce5',\n",
       " 92: 'cc3b5002-f1d6-49be-ac6d-c3570e64169f',\n",
       " 93: '44e10182-285b-4180-9fde-e4232897c6c1',\n",
       " 94: 'f09faee5-0156-45c6-bd93-290ba7b14452',\n",
       " 95: '26d38a0a-feda-4df4-accf-fce3961d7cf3',\n",
       " 96: '73023919-afad-42be-b2ba-a2145fa2fd6f',\n",
       " 97: 'b25e3cad-0914-4738-8f8d-1869516badbc',\n",
       " 98: '98b63686-0217-4002-812a-b31d2f30589a',\n",
       " 99: '88204353-d10a-4b04-ab9a-43dba5ed8472',\n",
       " 100: 'ab2f478b-2f89-4286-a423-905f7f4490da',\n",
       " 101: 'eb9cf973-67e3-49d0-a88d-fad7739495b5',\n",
       " 102: '4676b1a5-3533-45fe-a761-c431450f9b65',\n",
       " 103: 'b9ac6472-2b8e-437b-9086-a46a8eaa6873',\n",
       " 104: '9de0b20b-0e96-4d1b-90c1-7d3889ea0eea',\n",
       " 105: '367f9650-fba5-4a44-a39f-9d7b904e2dd6',\n",
       " 106: '7857aab2-f3af-4091-a2a4-1f0b5941c970',\n",
       " 107: '582321da-18e7-46e9-a8ca-318587bd39b2',\n",
       " 108: '8e140e8c-b3d2-4bb1-b525-e5da6704b959',\n",
       " 109: '407e2108-ee3b-4049-9fe9-dc93daf22f19',\n",
       " 110: 'b8c7a122-952b-4d8e-bd98-eac191c7afd5',\n",
       " 111: '925742ac-659e-4cee-aa0f-84a6c1f3e528',\n",
       " 112: '8e13f97c-0150-49d7-8746-6edc5e3d8089',\n",
       " 113: '29bd8a65-ec62-4e59-9651-db4c7b8115f6',\n",
       " 114: '5d293104-030d-4f7b-b8d3-cfebedc687a1',\n",
       " 115: '4446154b-1b3d-4df3-9716-8c242a72b529',\n",
       " 116: '7e5ef20b-7a49-4bf8-81bd-40573f1e3ec8',\n",
       " 117: '52abec85-58f5-4032-9082-4d34cbd05470',\n",
       " 118: 'eafcba59-6691-4e2d-abec-27c6bc8f33a7',\n",
       " 119: '7cb352b6-819d-4816-b3b2-ba2d2f50a660',\n",
       " 120: '28c85677-43ab-4c56-911f-ff461678b7b7',\n",
       " 121: '7491d19a-330d-4a7f-8da8-7e8603b56eff'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQf5FrWqOZVp",
    "outputId": "6a09f8a7-96b9-46e9-9f13-c9461de413f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='28c85677-43ab-4c56-911f-ff461678b7b7', metadata={}, page_content=\"leave your comments uh below perhaps with your own opinion here are some questions for you to consider are you optimistic or pessimistic about this or some kind of combination of the two do you use AI at the moment how do you use it could AI be a threat to your job one day or will it open new possibilities and new opportunities for your work do you use AI to help you learn English and will English teachers all be out of a job in the next few years would you choose me over my AI alternative there's a question anyway thank you so much for listening if you look at the PDF you'll see a full vot vocabulary list of all the highlighted bits of vocab in a list and also another list with loads of um uh all of that those bits of vocab with definitions examples and commentary so tons more detail on the PDF which you can just download just freely from the episode show notes but that's it that's the end of this episode thank you so much for watching or listening quite I just dumped all sorts of\")]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.get_by_ids(['28c85677-43ab-4c56-911f-ff461678b7b7'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce3f1sBQPNAG"
   },
   "source": [
    "# Step 2 - Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z__LBwouO36x",
    "outputId": "5856908f-b45f-42dd-d4c5-a8a8b306d7c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fcbc39564b0>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSrVaZhOPQv_",
    "outputId": "008e623c-7f72-4472-dd92-edb3b3e7ace1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='4f285562-3792-4910-aa59-bc1a5cfea855', metadata={}, page_content=\"mean that's just speaking personally probably what would be more likely is that you'd end up with maybe a lot of a loss a large loss of human life like we've seen in the past in Global Wars but where maybe a a certain percentage of the human race would survive and that would probably be the Richer ones anyway um are you quite worried about extinction level events events at a level that could cause the extinction of the human race we talk about Extinction of animals the dinosaurs are extinct um an extinction level event for the dinosaurs was the impact of several um as asteroids that hit the earth causing all sorts of environmental uh you know challenges that most of the dinosaurs couldn't deal with and they became extinct okay um and Jeffrey said we should distinguish these different risks so distinguish something means make a difference between them we should distinguish these different risks show that this risk is different to this risk so he talks about the risk of using a for\"),\n",
       " Document(id='710634ab-5d61-4297-94fc-2a7bd9cd2bd2', metadata={}, page_content=\"is um that's a possibility for the future so potential threats threats that could happen in the future uh we're talking about potential control threats meaning uh whether we will be able to control this technology and existential threats meaning threats to our very existence as the human race which sounds a little bit what's the word for it as I said paranoid maybe alarmist but actually when you hear what uh this man has to say you realize that it's actually quite reasonable and quite rational to have these these fears about these threats potential dangers so here are the highlights of what was said in the interview and I will expand on these things later in the episode but here's a here's a general overview of the main points so first of all AI is expected to exceed human intelligence soon as I said many experts are concerned about the existential threat posed by Advanced AI the existential threat posed by Advanced ai ai the AI represents or is or poses presents a big threat to human\"),\n",
       " Document(id='48afc2c6-008e-4c69-b666-cad899731eb9', metadata={}, page_content=\"and existential threats okay so experts believe that AI will exceed human intelligence in 5 to 20 years it'll exceed human intelligence meaning it'll it will become greater than right it'll go higher human intelligence is here at this level and AI will get to a higher level than that it will exceed human intelligence in up to 20 years raising concerns meaning making people concerned so if you raise concerns about something it means that people's concerns or or worries about a certain subject are raised they go up right to raise something means to make something go up rise means go up so people's concerns rise and uh this information raises people's concerns about potential control and existential threats potential means it's it's possible it could happen in the future it's something that is um that's a possibility for the future so potential threats threats that could happen in the future uh we're talking about potential control threats meaning uh whether we will be able to control\"),\n",
       " Document(id='60eb014a-afc9-4766-870f-62594bbcfad7', metadata={}, page_content=\"risks so distinguish something means make a difference between them we should distinguish these different risks show that this risk is different to this risk so he talks about the risk of using a for autonomous lethal weapons doesn't depend on AI being smarter than us so there's the use of AI for Weaponry by humans and then there's another risk which is that AI on its own Auto uh autonomously choosing to uh attack the human race so these are two different risks and he says that he's worried about both so the one risk is just humans using AI to kill kill other humans and the other one is like AI going rogue so he uses this expression the risk that AI itself will go Rogue and try to take over so to go Rogue means to kind of um H have you seen Mission Impossible the mission impossible films there's one called Rogue Nation right R Mission Impossible Rogue Nation also it makes me think of um cuz you know I I understand all issues through the context of Pop Culture uh movie plot lines um\")]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('What all risks associated?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAD7k-WsQPbC"
   },
   "source": [
    "# Step 3 - Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "bcb499eb591f4c4486f2a380394f85ac",
      "8c583160edff4b14afdd68441e77634e",
      "f35192ea8a684e2996fc27ecb08bf523",
      "7ac9af2a6c01471692498e925c4edcc5",
      "ed392c11eb83453c92d39bac677528d2",
      "4515184567034a969d0db5b958484a44",
      "0325db1f8a3f429e8cc7a8443eb6dcd9",
      "ba0293349440429294942ace9b1b5fde",
      "2117a1ea4a3f4d7a81d382508d5c4b5b",
      "b1c5fb83e44e4253b9aedf61ac2e6f83",
      "c198c0f3a53a44c387c84e3a1c79b62b",
      "b09ef86c82c440e1b036102e083a1a35",
      "a31b1f14ba9e471998525d5986a9e8fd",
      "3633eaed57fe41b9b836a9d6d9746dd7",
      "696ffe39da0b401ebf92052eefda965f",
      "08efb3c49d724a2386746d4f6fd622d4",
      "425380dee02c434ab26a7222f00c6728",
      "ef57ee6821e04c7c8e23b4cb2203bd5c",
      "ee4ee8ba94984cb0abf43e4dcf9d5285",
      "4fa6c1287a444e32949b49069a25bab9",
      "e2018a75a44348cc98ce6807f805e6d7",
      "f9547c46599c44d79478f4dbd618720c",
      "25dac8808b1749dcb57774903fa3112b",
      "505b897cfa58415ba13b0a3b9647f62a",
      "ebff4443e20c41529a705b80a9e109c1",
      "c0d65bc34f36483fa7a04d3043b5a292",
      "f6683770a7d94818832b3835aa088ef8",
      "c984596a3a7240ff96b750b1218e7f62",
      "bbc855a6623c4404ba0da28d8a6312ff",
      "a99c787ff2b740acb7416939f54eaa5d",
      "146d0dcc3a384bfa99656e74bc9e975c",
      "067fc567de4e45baa3a2721337fd23eb",
      "5e1864f380b44140aa8b6763b96ec0bf",
      "5e7a6cf927e24dff94ff6b3fa9dbe665",
      "2a58e1d6481b420a9f7f2e9362948bee",
      "7f14ade3835c402280bba561e39bc4d8",
      "a8a57ece7d474b398731869eca96bfcb",
      "6916a5ff2a934067b371181856eb3230",
      "1c7149be085d47afbe6f859eb312731b",
      "54831f9593554f40aa0ddbdc7ec8b7aa",
      "f4546b65ed8c49b681f2ee3fa77a1416",
      "4ae00008f55c4575adf13e0feb1cfc69",
      "a74f2911de104bfdbbfaa99543bf09c6",
      "09659b640d1647e0b87c917656b3a204",
      "3fbc5d892e73442c97d3c9e109a4a9b6",
      "cdcbbe66260b41e4b96703a6f09d9daa",
      "50207ae4f249483b8220bcc253433e1c",
      "db6eb22e12a2432fb990864be5c63239",
      "fd6e6be34ae74ea79b322ab9670cf150",
      "b8804bedfa704b1f8203d17cb0576cd6",
      "fe9564b1e56949948e59bb5002ed6ad1",
      "1784979b112f475499913303f5a3b04e",
      "02c99bd8d32b40aa9a2e027580eb1dd0",
      "989416742de14f8dba4ac2d615b9d38a",
      "dee84ed2f8e44fb0bd47d879ec92e264",
      "534b09028f7e4b0a8c25f449a1840370",
      "9990c492c06f41efbb08fb4ffd0fe7c7",
      "1ee1eb12cafc412684745b47d3da04b2",
      "7d2bfa5a5a5b48e389999b1a953a3394",
      "48fd208be3df40ebadd948b4994016c8",
      "ee4a49ffd0d74552a1f8b5be345f6c64",
      "14f35c302f8a4d1b95906be6b99b6132",
      "0f883f6c591f4b048f8065506b080bc2",
      "16341d3146aa4d69963c9cff128abcf8",
      "03718841a9454fb689fdd396d83b9bf8",
      "d2af001c0aac429c8847ba2ef5597d40",
      "c417a81135a340eba49e8dab3836951c",
      "25695403ffbe402f819ddc12514c2679",
      "6e875c36fa4a486ba12376245e07cd75",
      "69fce61efd9941548002e6a244fe72f2",
      "2547b3abc0ae481dbba6b64200c4f19c",
      "ed2d58ff0e84436186a478b97941ae38",
      "e01358b9f15c458f8c940b782e93c933",
      "abed3b60424e41c6a3b4c5875a4eadb1",
      "7511feef24eb450d8c7b918cd20fadc4",
      "7d2708750b664b349563b903e0714d1f",
      "0e430710a4644c0f8e0c1f7d13604fcb"
     ]
    },
    "id": "yrOx9uiPP6tT",
    "outputId": "0de3436c-5b70-42b8-cbcb-e36ca4ac960c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb499eb591f4c4486f2a380394f85ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09ef86c82c440e1b036102e083a1a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dac8808b1749dcb57774903fa3112b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7a6cf927e24dff94ff6b3fa9dbe665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbc5d892e73442c97d3c9e109a4a9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534b09028f7e4b0a8c25f449a1840370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c417a81135a340eba49e8dab3836951c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\"\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bg4OzGt1SGsw",
    "outputId": "e542f63f-540e-4723-80d8-5150ee843733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Xkv4pIYRS3mh"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      {context}\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "9HUinWL6TM2M"
   },
   "outputs": [],
   "source": [
    "question          = \"is the topic of job security discussed in this video? if yes then what was discussed\"\n",
    "retrieved_docs    = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58ifiqhJTj2s",
    "outputId": "030de459-3563-4282-88e5-206099045dc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='582321da-18e7-46e9-a8ca-318587bd39b2', metadata={}, page_content=\"letting down their guard on safety meaning are they allowing AI to develop in dangerous ways because they're trying to race to become the leader in the in the marketplace and the answer is more or less yes it is um he said Google was concerned about its reputation meaning about what people thought of it and I think pretty much the answer was probably yes then the interviewer asks um Jeffrey for his comments on what jobs people should do what degrees they should do degrees means University qualifications Bachelor degrees master's degrees the interviewer says it it seems like the world is being thrown up thrown up in the air so if things are up in the air or if things are thrown up in the air it means they are sort of suddenly there's no Order anymore and uh we're not sure about anything everything's up in the air at the moment we can't be sure about anything so what would you advise somebody to study uh to to Surf this wave meaning the wave meaning the this trend in society to surf the\"),\n",
       " Document(id='05dfef1d-57d0-4543-8836-74c826e577dd', metadata={}, page_content=\"pipes in a home or in the street something like that will likely remain safe emphasizing the need for future job Readiness Readiness means being ready okay so that's again an overview of the things that were said in the interview we're going to go through the interview in a bit and look at the vocab and stuff but at this point I would like to ask you what do you think what do you think of all this what's your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction and you could write your reaction in the comments section now maybe you feel like you want to make criticisms like these ones and I'm about to read out some comments which are based on things I I read in the comments section under the BBC video so maybe you want to make criticisms like this maybe you want to say things like this maybe he maybe this expert should have done something about this earlier when he had the chance he's\"),\n",
       " Document(id='76195ffd-a462-4004-90c8-d1f63fba4cad', metadata={}, page_content=\"serious and it's not really an emergency so that's what it means to be alarm IST is to perhaps maybe overreact about something um and you know overreact about the seriousness or the um uh the level of emergency going on so without being alarmist or paranoid or anything we could be looking at deeply profound changes to everything as a result of the continued development of of AI that's what this episode is about that's what I really want to talk about today and I was inspired to do this episode after I watched an interview with one of the world's leading experts on AI um I don't know you might have seen it too it's a video that's been going around on YouTube BBC News night interview with um what with who is described as uh The Godfather of AI so I found it absolutely fascinating as well as quite disturbing so it's an interview with the Nobel prizewinning Godfather of AI Jeffrey Hinton the interview took place earlier this year on BBC News night which is an evening news and current\"),\n",
       " Document(id='f18534e3-4aa8-4703-8c75-396b2764f3c8', metadata={}, page_content=\"as quite disturbing so it's an interview with the Nobel prizewinning Godfather of AI Jeffrey Hinton the interview took place earlier this year on BBC News night which is an evening news and current affairs TV show on the BBC the interview was then uploaded to the BBC News Night YouTube channel this month October that's the month when I'm recording this which is where I saw it so this is from the video description this is a description of the interview so Jeffrey Hinton former vice president of Google and sometimes referred to as the Godfather of AI I has recently won the 2024 Nobel physics prize so this guy used to be vice president of Google and is or has been referred to as the Godfather of AI so this is a person who is definitely an expert in this subject he recently won the 2024 Nobel physics prize he resigned from Google in 2023 he resigned that means he quit his job um not sure exactly the reasons why but he stepped down from his position at Google uh last year and has warned\")]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "xt5CbvCGTmsO",
    "outputId": "5601c5f9-8645-405b-f7ab-df3acbdbe5a4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"letting down their guard on safety meaning are they allowing AI to develop in dangerous ways because they're trying to race to become the leader in the in the marketplace and the answer is more or less yes it is um he said Google was concerned about its reputation meaning about what people thought of it and I think pretty much the answer was probably yes then the interviewer asks um Jeffrey for his comments on what jobs people should do what degrees they should do degrees means University qualifications Bachelor degrees master's degrees the interviewer says it it seems like the world is being thrown up thrown up in the air so if things are up in the air or if things are thrown up in the air it means they are sort of suddenly there's no Order anymore and uh we're not sure about anything everything's up in the air at the moment we can't be sure about anything so what would you advise somebody to study uh to to Surf this wave meaning the wave meaning the this trend in society to surf the\\n\\npipes in a home or in the street something like that will likely remain safe emphasizing the need for future job Readiness Readiness means being ready okay so that's again an overview of the things that were said in the interview we're going to go through the interview in a bit and look at the vocab and stuff but at this point I would like to ask you what do you think what do you think of all this what's your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction and you could write your reaction in the comments section now maybe you feel like you want to make criticisms like these ones and I'm about to read out some comments which are based on things I I read in the comments section under the BBC video so maybe you want to make criticisms like this maybe you want to say things like this maybe he maybe this expert should have done something about this earlier when he had the chance he's\\n\\nserious and it's not really an emergency so that's what it means to be alarm IST is to perhaps maybe overreact about something um and you know overreact about the seriousness or the um uh the level of emergency going on so without being alarmist or paranoid or anything we could be looking at deeply profound changes to everything as a result of the continued development of of AI that's what this episode is about that's what I really want to talk about today and I was inspired to do this episode after I watched an interview with one of the world's leading experts on AI um I don't know you might have seen it too it's a video that's been going around on YouTube BBC News night interview with um what with who is described as uh The Godfather of AI so I found it absolutely fascinating as well as quite disturbing so it's an interview with the Nobel prizewinning Godfather of AI Jeffrey Hinton the interview took place earlier this year on BBC News night which is an evening news and current\\n\\nas quite disturbing so it's an interview with the Nobel prizewinning Godfather of AI Jeffrey Hinton the interview took place earlier this year on BBC News night which is an evening news and current affairs TV show on the BBC the interview was then uploaded to the BBC News Night YouTube channel this month October that's the month when I'm recording this which is where I saw it so this is from the video description this is a description of the interview so Jeffrey Hinton former vice president of Google and sometimes referred to as the Godfather of AI I has recently won the 2024 Nobel physics prize so this guy used to be vice president of Google and is or has been referred to as the Godfather of AI so this is a person who is definitely an expert in this subject he recently won the 2024 Nobel physics prize he resigned from Google in 2023 he resigned that means he quit his job um not sure exactly the reasons why but he stepped down from his position at Google uh last year and has warned\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20QAjFcIT8cb",
    "outputId": "1a272c34-4088-48d2-9f27-24a70bc6c2e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"\\nYou are a helpful assistant.\\n      Answer ONLY from the provided transcript context.\\n      If the context is insufficient, just say you don't know.\\n\\n      letting down their guard on safety meaning are they allowing AI to develop in dangerous ways because they're trying to race to become the leader in the in the marketplace and the answer is more or less yes it is um he said Google was concerned about its reputation meaning about what people thought of it and I think pretty much the answer was probably yes then the interviewer asks um Jeffrey for his comments on what jobs people should do what degrees they should do degrees means University qualifications Bachelor degrees master's degrees the interviewer says it it seems like the world is being thrown up thrown up in the air so if things are up in the air or if things are thrown up in the air it means they are sort of suddenly there's no Order anymore and uh we're not sure about anything everything's up in the air at the moment we can't be sure about anything so what would you advise somebody to study uh to to Surf this wave meaning the wave meaning the this trend in society to surf the\\n\\npipes in a home or in the street something like that will likely remain safe emphasizing the need for future job Readiness Readiness means being ready okay so that's again an overview of the things that were said in the interview we're going to go through the interview in a bit and look at the vocab and stuff but at this point I would like to ask you what do you think what do you think of all this what's your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction and you could write your reaction in the comments section now maybe you feel like you want to make criticisms like these ones and I'm about to read out some comments which are based on things I I read in the comments section under the BBC video so maybe you want to make criticisms like this maybe you want to say things like this maybe he maybe this expert should have done something about this earlier when he had the chance he's\\n\\nserious and it's not really an emergency so that's what it means to be alarm IST is to perhaps maybe overreact about something um and you know overreact about the seriousness or the um uh the level of emergency going on so without being alarmist or paranoid or anything we could be looking at deeply profound changes to everything as a result of the continued development of of AI that's what this episode is about that's what I really want to talk about today and I was inspired to do this episode after I watched an interview with one of the world's leading experts on AI um I don't know you might have seen it too it's a video that's been going around on YouTube BBC News night interview with um what with who is described as uh The Godfather of AI so I found it absolutely fascinating as well as quite disturbing so it's an interview with the Nobel prizewinning Godfather of AI Jeffrey Hinton the interview took place earlier this year on BBC News night which is an evening news and current\\n\\nas quite disturbing so it's an interview with the Nobel prizewinning Godfather of AI Jeffrey Hinton the interview took place earlier this year on BBC News night which is an evening news and current affairs TV show on the BBC the interview was then uploaded to the BBC News Night YouTube channel this month October that's the month when I'm recording this which is where I saw it so this is from the video description this is a description of the interview so Jeffrey Hinton former vice president of Google and sometimes referred to as the Godfather of AI I has recently won the 2024 Nobel physics prize so this guy used to be vice president of Google and is or has been referred to as the Godfather of AI so this is a person who is definitely an expert in this subject he recently won the 2024 Nobel physics prize he resigned from Google in 2023 he resigned that means he quit his job um not sure exactly the reasons why but he stepped down from his position at Google uh last year and has warned\\n      Question: is the topic of job security discussed in this video? if yes then what was discussed\\n    \")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMaORVmqUbJM"
   },
   "source": [
    "# Step 4 - Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M15__7yoUMA7",
    "outputId": "59ba1463-0209-4893-c0fd-c2a6836513fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the need for future job Readiness Readiness means being ready okay so that's again an overview of the things that were said in the interview we're going to go through the interview in a bit and look at the vocab and stuff but at this point I would like to ask you what do you think what do you think of all this what's your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction now when you watch a video like this with an expert giving serious warnings or just listen to me rambling on about it all what is your reaction now when you watch a video like this with an expert giving serious warnings or just listen\n"
     ]
    }
   ],
   "source": [
    "answer = llm.invoke(final_prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "gnZwY7pyUl2A"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "SrPBjch1axjN"
   },
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "  return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "WMNueO8Va_Kj"
   },
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vS4znThbhRT",
    "outputId": "b3747555-022f-4ac8-9a89-d0aa94a60457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"just a kind of a a dramatic science fiction story but this is this stuff is becoming alarmingly close to reality um let's move on to the next point which is global regulation gaps which is what what I've been talking about current International agreements lack enforceability to enforce law means to basically apply law and actually make it work for example the police can enforce law or courts can enforce law essentially um finding people guilty of crimes if these laws are broken so this is this is how we talk about the enforceability enforcing law applying law in the real world so current International agreements lack enforceability regarding military uses of AI so it it basically the the the the laws are not quite strong enough or clear enough enough to be able to actually control people's behavior potentially leading to unchecked advancements by Nations right um unchecked meaning unregulated the idea of humans controlling lethal AI with no regulations is more frightening than the\\n\\nregulation that would limit the application or use of AI in military situations this is this this is one of the most terrifying aspects of this also AI could widen the wealth Gap right the Gap this is the gap between the W the the rich and the poor okay the the fact that there's you know a huge difference a huge disparity between those people who are rich and those people who are poor and I mean really the way it works is that there there's an increasingly small number of people who are becoming increasingly Rich so you get you get to a situation where there's a kind of a a small minority very small minority who have uh most of the money and then all the other people uh relatively speaking have very little money so you end up with this big gap between poor people and rich people so there's this huge imbalance in society so AI could widen this Gap make it wider make it bigger affecting Society negatively and plumbing may be one of the safest jobs in the age of AI Plumbing refers to uh\\n\\nagain sounds paranoid and alarmist but you know just wait and see so International regulation of military AI applications is lacking so International regulation this is basically applying rules to control things so you know different jurisdictions Global or local you know whether it's like EU law or some sort of global convention um these this is what we mean by regulation so systems of rules and laws to control things so International regulation of military AI this is artificial intelligence used in military applications so when we say applications that means not applications on your phone but in in uses the ways in which uh in this case AI is used so that's military applications that would be using AI for military purposes so regulation of this is lacking so there's not enough control or regulation that would limit the application or use of AI in military situations this is this this is one of the most terrifying aspects of this also AI could widen the wealth Gap right the Gap this\\n\\nmeans that we really need to start stepping in and making Global laws that limit the use of AI in uh military conflicts and it's obvious why right I mean we're looking at an arms race just like um you know just like the oldfashioned arms race of the Cold War the space race and all that stuff um but you know um there's a significant risk of of you know because um any regulations about AI they always have a clause in in the law that sort of say actually but none of these rules apply to military AI because everyone is so concerned about defending themselves or trying to compete with uh Rivals uh in on Earth who might be developing the the technology more quickly because no one wants to be in a situation where suddenly they're faced with an enemy who's got more sophisticated artificial intelligence and using it for military purposes because then you know they take over the world right but we need to find a way for the for Earth to agree on a set of regulations a bit like the way we've\",\n",
       " 'question': 'who are Global Regulation gaps'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke('who are Global Regulation gaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "cNIw0VMMbt2U"
   },
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "yAxErDXScFuv"
   },
   "outputs": [],
   "source": [
    "main_chain = parallel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "pnw6t73qcNOg",
    "outputId": "ec82198c-2a94-4aa8-99e6-d61307e5b2d0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"the dangers of machines that could outsmart humans so to outsmart humans means to to be more intelligent than humans so he's talking about the danger the possible the possibility that machines or AI in the future could become more intelligent than humans could outsmart humans so let me summarize the video and then go through the script of the interview giving my explanations and comments and AI in the future could become more intelligent than humans could outsmart humans so let me summarize the video and then go through the script of the interview giving my explanations and comments and of course explaining and highlighting certain bits of vocabulary if there's time I'll do a vocabulary recap at the end and certainly on the PDF you'll see a full vocabulary list with definitions examples and comments so that uh BBC News night interview it's available on YouTube\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chain.invoke('Can you provide important 3 to 4 points from the video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6WGGwkGcTfz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
